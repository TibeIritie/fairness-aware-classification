{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "679ef775-712f-4ef9-ba35-a83b5939feaf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Import modules & define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cf5ebf6-4206-417f-8b9f-83b6b60a75b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "from winsound import Beep\n",
    "from math import floor, ceil, sqrt\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.optimize import minimize\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "state = 0\n",
    "t0 = time()\n",
    "# Paths to save code ouputs, optimized weights, distance matrices, metrics & graphs\n",
    "path = 'Code outputs/'\n",
    "d_path = 'Code outputs/Fair Relabeling/Distance matrices/'\n",
    "w_path = 'Code outputs/Fair Relabeling/Weights/'\n",
    "m_path = 'Code outputs/Metrics/'\n",
    "g_path = 'Code outputs/Graphs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1328b828-e1d3-467b-adf5-94ae942d0ff0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f021261-d686-4688-890b-777965e7c535",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9a929e8-ec88-44d3-a96e-6c3f468bcd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_whitespace(df):\n",
    "    \"\"\"\n",
    "        Removes whitespaces in a dataframe\n",
    "\n",
    "        :param df: dataframe\n",
    "        :return: dataframe without whitespaces\n",
    "        \"\"\"\n",
    "    \n",
    "    for col in df:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].map(str.strip)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87ac07f3-bcfb-49b2-984a-746c6e8a4e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_constant_cols(df):\n",
    "    \"\"\"\n",
    "        Drop all constant and empty columns of dataframe\n",
    "        \n",
    "        :param df: dataframe with constant/empty columns\n",
    "        :return: dataframe without constant/empty columns\n",
    "        \"\"\"\n",
    "    \n",
    "    dropped_cols = []\n",
    "    for col in df:\n",
    "        if df[col].nunique() < 2:\n",
    "            df = df.drop([col], axis=1)\n",
    "            dropped_cols.append(col)\n",
    "    print(f'Dropped constant columns: {dropped_cols}')\n",
    "    print()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7782217-bfb5-474e-a19a-5664b82e7882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_encode(df_copy, enc_cols):\n",
    "    \"\"\"\n",
    "        Ordinal encode attributes, this function is also used for attributes with no natural order, \n",
    "        since some functions require numerical attributes \n",
    "\n",
    "        :param df_copy: dataframe with all (mixed type) data\n",
    "        :param enc_cols: list with column names to encode\n",
    "        :return: dataframe with ordinal encoded attributes\n",
    "    \"\"\"\n",
    "\n",
    "    df = df_copy.copy()\n",
    "    oe = OrdinalEncoder()\n",
    "    # Remove missing values before encoding because missing values are also encoded!\n",
    "    x_enc = oe.fit_transform(df[enc_cols]).astype(int)\n",
    "    df = df.drop(enc_cols, axis=1)\n",
    "    # Need to reset index of df, because index of pd.DataFrame(x_enc, columns=enc_cols) is also resetted\n",
    "    df = df.reset_index(drop=True)\n",
    "    df[enc_cols] = pd.DataFrame(x_enc, columns=enc_cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506ec103-a664-4d05-b44f-d449e5f5969b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f7549c4-78b3-4a41-b460-9f3de254554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_type(df, return_type):\n",
    "    \"\"\"\n",
    "        Returns all columns in a dataframe with column type = return_type\n",
    "\n",
    "        :param df: dataframe\n",
    "        :param return_type: column type to return\n",
    "        :return: list with columns\n",
    "        \"\"\"\n",
    "    \n",
    "    groups = df.columns.to_series().groupby(df.dtypes).groups\n",
    "    dictionary = {key.name: value for key, value in groups.items()}\n",
    "    return_type = list(dictionary[return_type])\n",
    "    return return_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82299184-654c-421c-8706-5b60f5b4d531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_df_info(df, c=None, extra=None):\n",
    "    \"\"\"\n",
    "        Prints shape of df, % of duplicate rows, %/size of deprived/favored group\n",
    "\n",
    "        :param df: dataframe\n",
    "        :param c: column to print histogram of\n",
    "        :param extra: whether to print the columns that are at risk of having an average binsize smaller than 70\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "    \n",
    "    s = df.columns[1]\n",
    "\n",
    "    print(f'Shape of df: {df.shape}')\n",
    "    print(f'Percentage of duplicate rows: {round((len(df) - len(df.drop_duplicates())) / df.shape[0], 4)}')\n",
    "    print(f'Percentage of duplicate rows (attributes only): '\n",
    "          f'{round((len(df.iloc[:, 1:]) - len(df.iloc[:, 1:].drop_duplicates())) / df.shape[0], 4)}')\n",
    "    print()\n",
    "    print(f'Value count for {s}:\\n{df[s].value_counts()}')\n",
    "    print()\n",
    "    print(f'Percentage for {s}:\\n{df[s].value_counts(normalize=True).round(4)}')\n",
    "    print()\n",
    "    exclude_cols = []\n",
    "    for col in df:\n",
    "        if df[col].nunique() != 0:\n",
    "            if df.shape[0] / df[col].nunique() < 70:\n",
    "                if extra:\n",
    "                    average_bin_size = round(df.shape[0] / df[col].nunique(), 1)\n",
    "                    print(col, f'({df[col].dtype})')\n",
    "                    print(f'Number of unique values: {df[col].nunique()} ({average_bin_size})')\n",
    "                    print(f'Unique values: {df[col].unique()}')\n",
    "                    print()\n",
    "                exclude_cols.append(col)\n",
    "        else:\n",
    "            exclude_cols.append(col)\n",
    "    if extra:\n",
    "        print(exclude_cols)\n",
    "    if c is not None:\n",
    "        print(f'Unique values in {c}: {np.sort(df[s].unique())}')\n",
    "        print()\n",
    "        df.hist(col=c)\n",
    "        print()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa459650-46ce-43b7-ab8d-9af6169ebc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(df, name, y):\n",
    "    \"\"\"\n",
    "        Run logistic regression of y (categorical) on df (excluding y).\n",
    "        \n",
    "        :param df: dataframe\n",
    "        :param name: name of dataset\n",
    "        :param y: dependent variable\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "    \n",
    "    cat_cols = list(df.select_dtypes(exclude='number').columns)\n",
    "    df_logit = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "    \n",
    "    num_cols = list(df.select_dtypes(include='number').columns)\n",
    "    scaler = MinMaxScaler()\n",
    "    df_logit[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "    \n",
    "    df_logit = df_logit.dropna()\n",
    "    log_reg = sm.Logit(df_logit[y[0]], df_logit.drop([y[0]], axis=1)).fit()\n",
    "    coefs_df_0 = log_reg.params.abs().to_frame(name=y[0])\n",
    "    log_reg = sm.Logit(df_logit[y[1]], df_logit.drop([y[1]], axis=1)).fit()\n",
    "    coefs_df_1 = log_reg.params.abs().to_frame(name=y[1])\n",
    "    coefs_df = coefs_df_0.merge(coefs_df_1, left_index=True, right_index=True, how='outer')\n",
    "    coefs_df.sort_values(by=y[1], ascending=False).to_excel(f'{path}{name}_coefficients.xlsx')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbfc00aa-7bd5-471e-8552-1d160d1d5fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histograms(df, a, cat_cols):\n",
    "    \"\"\"\n",
    "        Plot histogram for attribute a for the groups X^(d-), X^(f-), X^(-), X^(d+), X^(f+), X^(+)\n",
    "        ...\n",
    "        \n",
    "        \n",
    "        Methodology for interpreting histograms\n",
    "        ----------\n",
    "        Look at shape and median/mode of histograms!\n",
    "    \n",
    "        Definition redline/irrelevant attribute (w=0 if no explainable unfairness, w=small if explainable unfairness):\n",
    "        hist of X^(d-)/X^(d+) are similar and hist of X^(f-)/X^(f+) are similar, hist of X^(d-)/X^(f-) are different,\n",
    "        hist of X^(d+)/X^(f+) are different\n",
    "\n",
    "        Definition relevant (including explanatory) attribute (w=large): hist of X^(d-)/X^(d+) are different, \n",
    "        hist of X^(f-)/X^(f+) are different, \n",
    "        hist of X^(d-)/X^(f-) are similar if no explainable unfairness (approx sim if expl unf) \n",
    "        and hist of X^(d+)/X^(f+) are similar if no explainable unfairness (approx sim if expl unf)\n",
    "\n",
    "        hist of X^(-)/X^(+) is very different for relevant/explanatory attribute\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        :param df: dataframe\n",
    "        :param a: attribute to plot\n",
    "        :param cat_cols: list with column names of categorical attributes in df\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "\n",
    "    if a not in cat_cols:\n",
    "        a_max = df.loc[:, a].max()\n",
    "        a_min = df.loc[:, a].min()\n",
    "\n",
    "    neg = df[df.iloc[:, 0] == 0].loc[:, a]\n",
    "    pos = df[df.iloc[:, 0] == 1].loc[:, a]\n",
    "    d_neg = df[(df.iloc[:, 1] == 1) & (df.iloc[:, 0] == 0)].loc[:, a]\n",
    "    d_pos = df[(df.iloc[:, 1] == 1) & (df.iloc[:, 0] == 1)].loc[:, a]\n",
    "    f_neg = df[(df.iloc[:, 1] == 0) & (df.iloc[:, 0] == 0)].loc[:, a]\n",
    "    f_pos = df[(df.iloc[:, 1] == 0) & (df.iloc[:, 0] == 1)].loc[:, a]\n",
    "\n",
    "    plt.rc('font', **{'size': 6.5})\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(12, 6))\n",
    "\n",
    "    df_list = [[[0, 0], d_neg, r'$X^{d-}$'], [[0, 1], f_neg, r'$X^{f-}$'], [[0, 2], neg, r'$X^{-}$'],\n",
    "               [[1, 0], d_pos, r'$X^{d+}$'], [[1, 1], f_pos, r'$X^{f+}$'], [[1, 2], pos, r'$X^{+}$']]\n",
    "\n",
    "    for x in df_list:\n",
    "        if a not in cat_cols:\n",
    "            axs[x[0][0], x[0][1]].hist(x[1], range=(a_min, a_max), label=x[2], bins='rice')\n",
    "        else:\n",
    "            axs[x[0][0], x[0][1]].hist(x[1], label=x[2], bins='rice')            \n",
    "        if a in cat_cols:\n",
    "            modes = x[1].mode()\n",
    "            for mode in modes:\n",
    "                axs[x[0][0], x[0][1]].axvline(mode, alpha=0.6, c='k', label=f'Mode: {mode}', linestyle='dashed')\n",
    "        else:\n",
    "            axs[x[0][0], x[0][1]].axvline(x[1].median(), alpha=0.6, c='k', label=f'Median: {round(x[1].median(), 2)}',\n",
    "                                          linestyle='dashed')\n",
    "        axs[x[0][0], x[0][1]].set_xlabel(a)\n",
    "        axs[x[0][0], x[0][1]].set_ylabel('Frequence')\n",
    "        axs[x[0][0], x[0][1]].legend()    \n",
    "        axs[x[0][0], x[0][1]].tick_params('x', labelrotation=90)\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5379ffe3-a19b-4cf2-8f18-aee964f18268",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Detect group unfairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7ae8816-0205-435f-917a-07b8749facd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_d_all(df):\n",
    "    \"\"\"\n",
    "        Returns all discrimination in a dataframe\n",
    "\n",
    "        :param df: dataframe (column 0 = class_label (positive decision = 1),\n",
    "        column 1 = sensitive attribute (deprived group = 1))\n",
    "        :return: D_all\n",
    "        \"\"\"\n",
    "\n",
    "    c = df.columns[0]\n",
    "    s = df.columns[1]\n",
    "    \n",
    "    n_f_plus = df[(df[s] == 0) & (df[c] == 1)].shape[0]\n",
    "    n_f = df[df[s] == 0].shape[0]\n",
    "    n_d_plus = df[(df[s] == 1) & (df[c] == 1)].shape[0]\n",
    "    n_d = df[df[s] == 1].shape[0]\n",
    "    d_all = n_f_plus / n_f - n_d_plus / n_d\n",
    "    \n",
    "    return d_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efeb04df-7b68-4db1-82a9-4c4efea1a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_d_unfair(df, d_all, cat_cols, e=None, n_bins=[10], print_vc=False, export=False, name=''):\n",
    "    \"\"\"\n",
    "        Calculate D_u (and value count) for number of bins specified in n_bins\n",
    "\n",
    "        :param df: dataframe (column 0 = class_label (positive decision = 1),\n",
    "        column 1 = sensitive attribute (deprived group = 1), column 2 = explanatory attribute)\n",
    "        :param d_all: all discrimination\n",
    "        :param cat_cols: list with column names of categorical attributes in df\n",
    "        :param e: list with explanatory attribute(s) (default=None)\n",
    "        :param n_bins: list with number of bins used to discretize the explanatory attribute \n",
    "        (this parameter only influences numerical (!='object') explanatory attributes) (default=10)\n",
    "        :param print_vc: print value count for discretized explanatory attributes) (default=True)\n",
    "        :param export: whether to export d_unfairs_df to an Excel file or not (default=True)\n",
    "        :param name: name of dataset (default='')\n",
    "        :return: D_u\n",
    "        \"\"\"\n",
    "    \n",
    "    global t0\n",
    "\n",
    "    t0 = time()\n",
    "    \n",
    "    c = df.columns[0]\n",
    "    s = df.columns[1]\n",
    "    if e is None:\n",
    "        e = [df.columns[2]]\n",
    "    \n",
    "    df_d = df.copy()\n",
    "    d_unfairs_df = pd.DataFrame(index=e)\n",
    "    svcs_df = pd.DataFrame(index=e)\n",
    "    for n in n_bins:\n",
    "        num_cols = []\n",
    "        d_fairs = []\n",
    "        svcs = []\n",
    "        for a in e:\n",
    "            if a not in cat_cols:\n",
    "                # Creating more bins than unique values is not necessarily wrong, \n",
    "                # since new data might add new unique values \n",
    "                # and more bins (empty bins) might reflect the distribution of the original data better\n",
    "                df_d[a] = pd.cut(df_d[a], n, labels=False)\n",
    "                num_cols.append(a)\n",
    "                vcs = df_d[a].value_counts().sort_values()\n",
    "                if print_vc:\n",
    "                    # Value counts are printed to check for small bins\n",
    "                    print(f'Value count for {a} (discretized):\\n{vcs}')\n",
    "                    print()\n",
    "            else:      \n",
    "                vcs = df_d[a].value_counts().sort_values()\n",
    "            e_values = df_d[a].unique().tolist()\n",
    "            d_fair = 0\n",
    "            for i in e_values:\n",
    "                p_e_f = df_d[(df_d[s] == 0) & (df_d[a] == i)].shape[0] / df_d[df_d[s] == 0].shape[0]\n",
    "                p_e_d = df_d[(df_d[s] == 1) & (df_d[a] == i)].shape[0] / df_d[df_d[s] == 1].shape[0]\n",
    "                if df_d[(df_d[s] == 0) & (df_d[a] == i)].shape[0] != 0:\n",
    "                    p_c_e_f = df_d[(df_d[s] == 0) & (df_d[a] == i) & (df_d[c] == 1)].shape[0] / \\\n",
    "                              df_d[(df_d[s] == 0) & (df_d[a] == i)].shape[0]\n",
    "                else:\n",
    "                    p_c_e_f = 0\n",
    "                if df_d[(df_d[s] == 1) & (df_d[a] == i)].shape[0] != 0:\n",
    "                    p_c_e_d = df_d[(df_d[s] == 1) & (df_d[a] == i) & (df_d[c] == 1)].shape[0] / \\\n",
    "                              df_d[(df_d[s] == 1) & (df_d[a] == i)].shape[0]\n",
    "                else:\n",
    "                    p_c_e_d = 0\n",
    "                p_star = (p_c_e_f + p_c_e_d) / 2\n",
    "                d_fair += (p_e_f - p_e_d) * p_star\n",
    "            d_fairs.append(d_fair)\n",
    "            svcs.append(vcs.iloc[0])\n",
    "            # Need to set df_d[a] to original column otherwise loop will continue with discretized column\n",
    "            df_d[a] = df[a]\n",
    "        d_unfairs_df[n] = [d_all - d for d in d_fairs]\n",
    "        svcs_df[n] = svcs\n",
    "    d_unfairs_df = d_unfairs_df.sort_values(by=[n_bins[0]])\n",
    "    svcs_df = svcs_df.reindex(d_unfairs_df.index)\n",
    "    if export:\n",
    "        d_unfairs_df.to_excel(f'{path}{name}_d_unfairs.xlsx')\n",
    "        svcs_df.to_excel(f'{path}{name}_smallest_value_counts.xlsx')\n",
    "    if len(n_bins) != 1:\n",
    "        total = (time() - t0) / 60\n",
    "        print(f'Total runtime (in minutes): {round(total, 2)}')\n",
    "    if len(e) == 1 and len(n_bins) == 1:\n",
    "        d_unfairs_df = d_unfairs_df.iloc[0, 0]\n",
    "    return d_unfairs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dcc4eaf-5e91-40b1-874e-c8a73f57ef4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_d_unfair_i(df, e, n_bins=[10], print_vc=True, export=True, name=''):\n",
    "    \"\"\"\n",
    "        Calculate D_u (in a different manner) for number of bins specified in n_bins\n",
    "\n",
    "        :param df: dataframe (column 0 = class_label (positive decision = 1),\n",
    "        column 1 = sensitive attribute (deprived group = 1), column 2 = explanatory attribute)\n",
    "        :param e: list with explanatory attribute(s)\n",
    "        :param n_bins: list with number of bins used to discretize the explanatory attribute \n",
    "        (this parameter only influences numerical (!='object') explanatory attributes) (default=10)\n",
    "        :param print_vc: print value count for discretized explanatory attributes) (default=True)\n",
    "        :param export: whether to export d_unfairs_df to an Excel file or not (default=True)\n",
    "        :param name: name of dataset (default='')\n",
    "        :return: D_u\n",
    "        \"\"\"\n",
    "    \n",
    "    global t0\n",
    "\n",
    "    t0 = time()\n",
    "    \n",
    "    c = df.columns[0]\n",
    "    s = df.columns[1]\n",
    "    if e is None:\n",
    "        e = [df.columns[2]]\n",
    "    \n",
    "    df_d = df.copy()\n",
    "    d_unfairs_df = pd.DataFrame(index=e)\n",
    "    for n in n_bins:\n",
    "        num_cols = []\n",
    "        # List with all d_unfairs for n_bins = n\n",
    "        d_unfairs = []\n",
    "        for a in e:\n",
    "            if df_d[a].dtype != 'object':\n",
    "                df_d[a] = pd.cut(df_d[a], n, labels=False)\n",
    "                num_cols.append(a)\n",
    "                if print_vc:\n",
    "                    # Value counts are printed to check for small bins\n",
    "                    print(f'Value count for {a} (discretized):\\n{df_d[a].value_counts().sort_values()}')\n",
    "                    print()\n",
    "            e_values = df_d[a].unique().tolist()\n",
    "            d_unfair = 0\n",
    "            n_es = 0\n",
    "            for i in e_values:\n",
    "                n_e = df_d[df_d[a] == i].shape[0]\n",
    "                n_es += n_e\n",
    "                if df_d[(df_d[s] == 0) & (df_d[a] == i)].shape[0] != 0:\n",
    "                    pr_f_e = df_d[(df_d[s] == 0) & (df_d[a] == i) & (df_d[c] == 1)].shape[0] / \\\n",
    "                             df_d[(df_d[s] == 0) & (df_d[a] == i)].shape[0]\n",
    "                else:\n",
    "                    pr_f_e = 0\n",
    "                if df_d[(df_d[s] == 1) & (df_d[a] == i)].shape[0] != 0:\n",
    "                    pr_d_e = df_d[(df_d[s] == 1) & (df_d[a] == i) & (df_d[c] == 1)].shape[0] / \\\n",
    "                             df_d[(df_d[s] == 1) & (df_d[a] == i)].shape[0]\n",
    "                else:\n",
    "                    pr_d_e = 0\n",
    "                d_unfair += n_e * (pr_f_e - pr_d_e)\n",
    "            d_unfairs.append(d_unfair / n_es)\n",
    "            # Need to set df_d[a] to original column otherwise loop will continue with discretized column\n",
    "            df_d[a] = df[a]\n",
    "        d_unfairs_df[n] = d_unfairs\n",
    "    d_unfairs_df = d_unfairs_df.sort_values(by=[n_bins[0]])\n",
    "    if export:\n",
    "        d_unfairs_df.to_excel(f'{path}{name}_d_unfairs_i.xlsx')\n",
    "    if len(n_bins) != 1:\n",
    "        total = (time() - t0) / 60\n",
    "        print(f'Total runtime (in minutes): {round(total, 2)}')\n",
    "    if len(e) == 1 and len(n_bins) == 1:\n",
    "        d_unfairs_df = d_unfairs_df.iloc[0, 0]\n",
    "    return d_unfairs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d62ff3-328b-4f77-8986-06071533349f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8543a3d-ae45-44ad-a942-54f472cf1ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(clf, name, df_copy, cat_cols, nom_cols, method='', params=None, test=False, drop_s=False,\n",
    "          no_print=False):\n",
    "    \"\"\"\n",
    "        Predict positive class probabilities using nested stratified cv\n",
    "\n",
    "        :param clf: instance of classifier (use clf=None for NBS)\n",
    "        :param name: name of classifier\n",
    "        :param df_copy: dataframe (column 0 = class_label (positive decision = 1),\n",
    "        column 1 = sensitive attribute (deprived group = 1), column 2 = explanatory attribute)\n",
    "        :param cat_cols: list with column names of categorical attributes in df_copy (needed for NBS)\n",
    "        :param nom_cols: list with column names of nominal attributes in df_copy (needed for one-hot-encoding)\n",
    "        :param method: pre-processing method '', 'frw', 'fps' or 'frl' (default='')\n",
    "        :param params: dataframe with tuning parameters as columns names for 'frw',  \n",
    "        list with sampled dataframes for 'fps' or list with relabeled dataframes for 'frl'\n",
    "        (default=None, no pre-processing)\n",
    "        :param test: whether to make predictions for the test or validation set (default=False)\n",
    "        :param drop_s: whether to drop the sensitive attribute for training/prediction or not (default=False)\n",
    "        :param no_print: whether to not print anything or print everything (default=False,\n",
    "        =True when tuning hyperparameters for DT)\n",
    "        :return: positive class probabilities for all instances using the validation and test set\n",
    "    \"\"\"\n",
    "\n",
    "    global t0\n",
    "\n",
    "    t0 = time()\n",
    "\n",
    "    df = df_copy.copy()\n",
    "    # Code below assumes df is sorted on index\n",
    "    df = df.sort_index()\n",
    "\n",
    "    if drop_s:\n",
    "        x = df.iloc[:, 2:]\n",
    "        if df.columns[1] in cat_cols:\n",
    "            cat_cols.remove(df.columns[1])\n",
    "    else:\n",
    "        x = df.iloc[:, 1:]\n",
    "\n",
    "    y = df.iloc[:, 0]\n",
    "    s = df.iloc[:, 1]\n",
    "    e = df.iloc[:, 2]\n",
    "\n",
    "    # kk-NN/DT/Logit cannot work with nominal attributes, NBS uses ordinal encoding in get_y_pr_nbs()\n",
    "    if name == 'knn' or name == 'dt':\n",
    "        x = pd.get_dummies(x, columns=nom_cols)\n",
    "    if name == 'logit':\n",
    "        x = pd.get_dummies(x, columns=nom_cols, drop_first=True)\n",
    "\n",
    "    i, j = 0, 0\n",
    "    # r, k are the number of folds for the outer and inner loop\n",
    "    r, k = 5, 4\n",
    "    cv_outer = StratifiedKFold(n_splits=r, shuffle=True, random_state=state)\n",
    "\n",
    "    if params is not None:\n",
    "        y_pr_val_np = y_pr_test_np = np.empty(shape=(0, 1 + len(params[0])))\n",
    "        val_names = test_names = params[0]\n",
    "        # Parameter values (first list item) are not used anymore and thus (should be) disregarded\n",
    "        params.pop(0)\n",
    "        # 'ix' is also added to 'test_names'\n",
    "        val_names.insert(0, 'ix')\n",
    "    else:\n",
    "        y_pr_val_np = y_pr_test_np = np.empty(shape=(0, 2))\n",
    "        val_names = test_names = ['ix', 'y_prob']\n",
    "\n",
    "    # BEGIN OUTER LOOP\n",
    "    for train_1_ix, test_ix in cv_outer.split(x, y):\n",
    "        if not no_print:\n",
    "            print(f'Outer fold {i + 1}')\n",
    "        x_tr_1, x_te = x.iloc[train_1_ix], x.iloc[test_ix]\n",
    "        y_tr_1, y_te = y.iloc[train_1_ix], y.iloc[test_ix]\n",
    "        # train_1_ix/test_ix are new indices created by cv_outer.split(x, y)\n",
    "        # and equal to the indices found in x\n",
    "\n",
    "        if test:\n",
    "            y_pr_inner = np.empty(shape=(len(test_ix), 0))\n",
    "            # Set indices of test set as first column of y_pr_inner\n",
    "            y_pr_inner = np.hstack((y_pr_inner, np.array(test_ix)[:, None]))\n",
    "            if params is not None:\n",
    "                for param in params:\n",
    "                    y_pr_test = get_y_pr(clf, name, x_tr_1, y_tr_1, x_te, cat_cols, param, x.index[train_1_ix], method)\n",
    "                    y_pr_inner = np.hstack((y_pr_inner, y_pr_test[:, None]))\n",
    "            else:\n",
    "                y_pr_test = get_y_pr(clf, name, x_tr_1, y_tr_1, x_te, cat_cols)\n",
    "                y_pr_inner = np.hstack((y_pr_inner, y_pr_test[:, None]))\n",
    "            y_pr_test_np = np.vstack((y_pr_test_np, y_pr_inner))\n",
    "        else:\n",
    "            cv_inner = StratifiedKFold(n_splits=k, shuffle=True, random_state=state)\n",
    "            # BEGIN INNER LOOP\n",
    "            for train_2_ix, val_ix in cv_inner.split(x_tr_1, y_tr_1):\n",
    "                x_tr_2, x_val = x_tr_1.iloc[train_2_ix], x_tr_1.iloc[val_ix]\n",
    "                y_tr_2, y_val = y_tr_1.iloc[train_2_ix], y_tr_1.iloc[val_ix]\n",
    "                # train_2_ix/val_ix are new indices created by cv_inner.split(x_tr_1, y_tr_1),\n",
    "                # which are not equal to the indices found in x\n",
    "                # (indices of x_tr_1 do correspond to the indices of x)\n",
    "                original_val_ix = x_tr_1.index[val_ix]\n",
    "                original_tr_2_ix = x_tr_1.index[train_2_ix]\n",
    "\n",
    "                y_pr_inner = np.empty(shape=(len(original_val_ix), 0))\n",
    "                # Set indices of validation set as first column of y_pr_inner\n",
    "                y_pr_inner = np.hstack((y_pr_inner, np.array(original_val_ix)[:, None]))\n",
    "                if params is not None:\n",
    "                    # Fit model for each param value and make predictions for x_val\n",
    "                    for param in params:\n",
    "                        y_pr_val = get_y_pr(clf, name, x_tr_2, y_tr_2, x_val, cat_cols, param, original_tr_2_ix, method)\n",
    "                        y_pr_inner = np.hstack((y_pr_inner, y_pr_val[:, None]))\n",
    "                else:\n",
    "                    # First fit to calculate FNR's/FPR's! (for FRW/FPS)\n",
    "                    y_pr_val = get_y_pr(clf, name, x_tr_2, y_tr_2, x_val, cat_cols)\n",
    "                    y_pr_inner = np.hstack((y_pr_inner, y_pr_val[:, None]))\n",
    "\n",
    "                y_pr_val_np = np.vstack((y_pr_val_np, y_pr_inner))\n",
    "\n",
    "                # The code above assumes that the second column of .predict_proba contains the probabilities for class=1\n",
    "                if clf is not None:\n",
    "                    if not np.array_equal(clf.classes_, np.array([0, 1])):\n",
    "                        print(f'Warning classes = {clf.classes_}!')\n",
    "\n",
    "                j += 1\n",
    "                # END INNER LOOP\n",
    "        i += 1\n",
    "        # END OUTER LOOP\n",
    "        \n",
    "    if test:\n",
    "        y_pr_te_df = pd.DataFrame(y_pr_test_np, columns=test_names)\n",
    "        y_pr_te_df = y_pr_te_df.groupby('ix').mean().sort_index().reset_index(drop=True)\n",
    "        # y_pr_te_df is sorted by index so y, s, e (also sorted by index) can directly be added as column to y_pr_te_df\n",
    "        y_pr_te_df['y_true'], y_pr_te_df['s'], y_pr_te_df['e'] = y, s, e\n",
    "        y_pr_val_df = pd.DataFrame()\n",
    "    else:\n",
    "        y_pr_val_df = pd.DataFrame(y_pr_val_np, columns=val_names)\n",
    "        y_pr_val_df = y_pr_val_df.groupby('ix').mean().sort_index().reset_index(drop=True)\n",
    "        # y_pr_val_df is sorted by index so y, s, e (also sorted by index) can directly be added as column to y_pr_val_df\n",
    "        y_pr_val_df['y_true'], y_pr_val_df['s'], y_pr_val_df['e'] = y, s, e    \n",
    "        y_pr_te_df = pd.DataFrame()\n",
    "\n",
    "    total = (time() - t0) / 60\n",
    "    \n",
    "    if not no_print:\n",
    "        print(f'Total runtime (in minutes): {round(total, 2)}')\n",
    "        print()\n",
    "    if total > 1:\n",
    "        Beep(600, 1500)\n",
    "        \n",
    "    return y_pr_val_df, y_pr_te_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a8a5ad3-ccda-4205-afdb-dcb10a4364b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_pr(clf, name, x_tr, y_tr, x, cat_cols, param=None, tr_ix=np.empty(0), method=''):\n",
    "    \"\"\"\n",
    "        Predict positive class probabilities using clf + method\n",
    "\n",
    "        :param clf: instance of classifier (use clf=None for NBS)\n",
    "        :param name: name of classifier\n",
    "        :param x_tr: training attributes\n",
    "        :param y_tr: training class labels\n",
    "        :param x: test or validation attributes\n",
    "        :param cat_cols: list with column names of categorical attributes in df (needed for NBS)\n",
    "        :param param: dataframe column for 'frw', sampled dataframe for 'fps' or relabeled dataframe for 'frl'\n",
    "        (default=None, no pre-processing)\n",
    "        :param tr_ix: original training indices (default=np.empty(0))\n",
    "        :param method: pre-processing method '', 'frw', 'fps' or 'frl' (default='')\n",
    "        :return: positive class probabilities for x\n",
    "    \"\"\"\n",
    "    \n",
    "    if param is not None:\n",
    "        if method == 'frw':\n",
    "            if name == 'nbs':\n",
    "                y_pr = get_y_pr_nbs(x_tr, y_tr, x, cat_cols, param[tr_ix])\n",
    "            elif name == 'knn':\n",
    "                # knn does not work with sample_weights\n",
    "                y_pr = clf.fit(x_tr, y_tr.values.ravel()).predict_proba(x)[:, 1]\n",
    "            else:\n",
    "                y_pr = clf.fit(x_tr, y_tr.values.ravel(), param[tr_ix]).predict_proba(x)[:, 1]\n",
    "        if method == 'fps' or method == 'frl':\n",
    "            tr_pp = param.loc[tr_ix]\n",
    "            if name == 'nbs':\n",
    "                y_pr = get_y_pr_nbs(tr_pp.iloc[:, 1:], tr_pp.iloc[:, 0], x, cat_cols)\n",
    "            else:\n",
    "                y_pr = clf.fit(tr_pp.iloc[:, 1:], tr_pp.iloc[:, 0]).predict_proba(x)[:, 1]\n",
    "    else:\n",
    "        if name == 'nbs':\n",
    "            y_pr = get_y_pr_nbs(x_tr, y_tr, x, cat_cols)\n",
    "        else:\n",
    "            y_pr = clf.fit(x_tr, y_tr.values.ravel()).predict_proba(x)[:, 1]\n",
    "    return y_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a498938-593a-4a78-b34f-5438378a2061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_pr_nbs(x_tr, y_tr, x_te, cat_cols, sample_weight=None):\n",
    "    \"\"\"\n",
    "        Predict positive class probabilities for NBS with mixed typed data\n",
    "\n",
    "        :param x_tr: training attributes\n",
    "        :param y_tr: training class labels\n",
    "        :param x_te: test attributes (or validation attributes)\n",
    "        :param cat_cols: list with column names of categorical attributes in df\n",
    "        :param sample_weight: weights applied to instances (default=None)\n",
    "        :return: positive class probabilities for x_te\n",
    "    \"\"\"\n",
    "\n",
    "    x_tr_num, x_te_num = x_tr.drop(cat_cols, axis=1), x_te.drop(cat_cols, axis=1)\n",
    "    x_tr_cat, x_te_cat = x_tr[cat_cols], x_te[cat_cols]\n",
    "\n",
    "    oe = OrdinalEncoder()\n",
    "    x_tr_cat = oe.fit_transform(x_tr_cat).astype(int)\n",
    "    x_te_cat = oe.fit_transform(x_te_cat).astype(int)\n",
    "\n",
    "    clf_g = GaussianNB().fit(x_tr_num, y_tr.values.ravel(), sample_weight=sample_weight)\n",
    "    # If CategoricalNB sees a higher number of categories in x_te_cat then in x_tr_cat an error will be thrown!\n",
    "    if len(np.unique(x_tr_cat)) >= len(np.unique(x_te_cat)):\n",
    "        clf_c = CategoricalNB(min_categories=len(np.unique(x_tr_cat))).fit(x_tr_cat, y_tr.values.ravel(),\n",
    "                                                                           sample_weight=sample_weight)\n",
    "    else:\n",
    "        clf_c = CategoricalNB(min_categories=len(np.unique(x_te_cat))).fit(x_tr_cat, y_tr.values.ravel(),\n",
    "                                                                           sample_weight=sample_weight)\n",
    "\n",
    "    proba_g = clf_g.predict_proba(x_te_num)\n",
    "    proba_c = clf_c.predict_proba(x_te_cat)\n",
    "    proba_1 = np.multiply(proba_g, proba_c)\n",
    "    proba_2 = proba_1 / np.exp(clf_c.class_log_prior_)\n",
    "    # Normalization step\n",
    "    proba_3 = proba_2[:, 1] / proba_2.sum(axis=1)\n",
    "\n",
    "    return proba_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a142d021-4d36-4486-a7ad-b6091440b390",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Show metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccf241a1-8fba-4f1a-9583-e8702d547f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(df_y_prob, df_original_copy, d_matrix, m, name, cat_cols, n_bins=[10], t=0):\n",
    "    \"\"\"\n",
    "        Get accuracy, D_all, D_u, U and U_n for df\n",
    "\n",
    "        :param df_y_prob: dataframe with y_prob (for different parameter values, \n",
    "        where the first column are the baseline predictions), s, e, y_true\n",
    "        :param df_original_copy: original dataframe without any predictions or pre-processing\n",
    "        :param d_matrix: ndarray with distance matrix\n",
    "        :param m: m for measuring individual unfairness U using m-NN\n",
    "        :param name: name of dataset\n",
    "        :param cat_cols: list with column names of categorical attributes in df_original_copy\n",
    "        :param n_bins: number of bins used to discretize the explanatory attribute\n",
    "        :param t: unfairness threshold for (score > t ⇒ unfair, default=0)\n",
    "        :return: dataframe accuracy, D_all, D_u, U and U_n for all parameter values\n",
    "    \"\"\"\n",
    "\n",
    "    # Quick and dirty method to assign values to d_matrix and m, \n",
    "    # if they're acutally computed under 'Get weights, d_matrix, m for all datasets'\n",
    "    if len(d_matrix) == 0 or np.isnan(m):\n",
    "        if name == 'adult':\n",
    "            d_matrix, m, = d_matrix_adult, m_adult\n",
    "        if name == 'compas':\n",
    "            d_matrix, m, = d_matrix_compas, m_compas\n",
    "        if name == 'ar':\n",
    "            d_matrix, m, = d_matrix_ar, m_ar\n",
    "\n",
    "    # Exclude class label from copy original dataset, \n",
    "    # because metrics needs to be calculated for predictions, not the original class label\n",
    "    df_original = df_original_copy.iloc[:, 1:].copy()\n",
    "    metrics = np.empty(shape=(0, 5))\n",
    "    for param in df_y_prob.drop(['s', 'e', 'y_true'], axis=1):\n",
    "        # Rounding down\n",
    "        df_y_prob[param] = (df_y_prob[param] > 0.5).astype(int)\n",
    "        acc = accuracy_score(df_y_prob['y_true'], df_y_prob[param])\n",
    "        d_all = get_d_all(df_y_prob[[param, 's', 'e']])\n",
    "        d_u = get_d_unfair(df_y_prob[[param, 's', 'e']], d_all, cat_cols, n_bins=n_bins)\n",
    "        df_original.insert(0, 'y_prob', df_y_prob[param])\n",
    "        if len(d_matrix) != 0 and not np.isnan(m):\n",
    "            _, _, u, u_n = get_unfair_instances(df_original.to_numpy(), d_matrix, m, name, t)\n",
    "        else:\n",
    "            u, u_n = np.nan, np.nan\n",
    "        df_original = df_original.drop('y_prob', axis=1)\n",
    "        metrics = np.vstack((metrics, [acc, d_all, d_u, u, u_n]))\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics, index=list(df_y_prob.drop(['s', 'e', 'y_true'], axis=1).columns),\n",
    "                              columns=['Accuracy', 'D_all', 'D_u', 'U', 'U_n'])\n",
    "\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9b49313-8515-47c0-afa5-2c8333f909b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(df_list, name, d_u=True, save=True, no_print=False):\n",
    "    \"\"\"\n",
    "        Plot metrics for all dataframes in df\n",
    "\n",
    "        :param df_list: nested list with (1) dataframes with accuracy, D_all, D_u, U, U_n for each pre-processing method\n",
    "        (first row of each dataframe should be the baseline results), (2) names of techniques \n",
    "        and (3) the index of the FRL results (needs to be specified, because first row of FRL contains RL results)\n",
    "        :param name: name of plot\n",
    "        :param d_u: whether to plot D_u against the accuracy or U against the accuracy (default=True)\n",
    "        :param save: whether to save the plot or not (default=False)\n",
    "        :param no_print: whether to not print anything or print everything (default=False,\n",
    "        =True when tuning hyperparameters for DT)\n",
    "        :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    if not no_print:\n",
    "        print(name)\n",
    "\n",
    "    n_clf = len(df_list)\n",
    "    plt.rc('font', **{'size': 10})\n",
    "    if n_clf > 1:\n",
    "        fig, axs = plt.subplots(1, n_clf, figsize=(6.4 * n_clf, 4.8))\n",
    "    else:\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(12.8, 4.8))\n",
    "\n",
    "    if not d_u:\n",
    "        col_i = 3\n",
    "    else:\n",
    "        col_i = 2\n",
    "\n",
    "    # Iterate over classifiers or dataset in df\n",
    "    for i, clf in enumerate(df_list):\n",
    "        df = clf[0]\n",
    "        names = clf[1]\n",
    "        # If no i_frl is provided set i_frl equal to a non existing index in df/names\n",
    "        if len(clf) == 2:\n",
    "            i_frl = len(df)\n",
    "        else:\n",
    "            i_frl = clf[2]\n",
    "        d_rds = 0\n",
    "        # Iterate over techniques in df\n",
    "        for j, d in enumerate(df):\n",
    "            if j == 0:\n",
    "                # Horizontal line at baseline (no pre-processing) accuracy\n",
    "                axs[i].axhline(y=d.iloc[0, 0], c='k', linestyle='dashed', linewidth=1)\n",
    "                # x at baseline (no pre-processing) col_i, accuracy\n",
    "                axs[i].plot(d.iloc[0, col_i], d.iloc[0, 0], color='k', label='Baseline', linestyle='dashed',\n",
    "                            linewidth=1, marker='x', markersize=7)\n",
    "                \n",
    "            # Create dataframe with rows for which reverse discrimination (D_u ≤ 0) occurs\n",
    "            if not d_u:\n",
    "                if j != i_frl and name != 'frl_knn':\n",
    "                    d_rd = d.iloc[1:, :].loc[d['D_u'] <= 0]\n",
    "                else:\n",
    "                    d_rd = d.iloc[2:, :].loc[d['D_u'] <= 0]\n",
    "            else:\n",
    "                d_rd = pd.DataFrame()\n",
    "            if not d_rd.empty:\n",
    "                d_rds += 1\n",
    "                if d_rds == 1:\n",
    "                    axs[i].scatter(d_rd.iloc[:, col_i], d_rd.iloc[:, 0], s=30, color='k', marker='+', label='$D_u$≤0',\n",
    "                                   linewidths=1)\n",
    "\n",
    "            if j == i_frl:\n",
    "                q = axs[i].plot(d.iloc[2:, col_i], d.iloc[2:, 0], marker='.', markersize=3, label=names[j], linewidth=1)\n",
    "                # Plot + for points where D_u <= 0\n",
    "                if not d_rd.empty:\n",
    "                    axs[i].scatter(d_rd.iloc[:, col_i], d_rd.iloc[:, 0], s=30, color=q[0].get_color(), marker='+',\n",
    "                                   linewidths=1)\n",
    "            else:\n",
    "                # Plot 1 point at baseline results for where frw_knn should've been\n",
    "                if (name == 'adult' or name == 'compas' or name == 'ar') and name[-3:] != 'knn':\n",
    "                    if i == 1 and j == 1:\n",
    "                        axs[i].plot(d.iloc[0, col_i], d.iloc[0, 0])\n",
    "                else:\n",
    "                    if name != 'nbs' and name != 'dt' and name != 'logit' and j == 1 and name[-3:] != 'knn':\n",
    "                        axs[i].plot(d.iloc[0, col_i], d.iloc[0, 0])\n",
    "                if name != 'frl_knn':\n",
    "                    # Plot col_i against accuracy for every dataframe in df\n",
    "                    r = axs[i].plot(d.iloc[1:, col_i], d.iloc[1:, 0], marker='.', markersize=3, label=names[j],\n",
    "                                    linewidth=1)\n",
    "                    # Plot + for points where D_u <= 0\n",
    "                    if not d_rd.empty:\n",
    "                        axs[i].scatter(d_rd.iloc[:, col_i], d_rd.iloc[:, 0], s=30, color=r[0].get_color(), marker='+',\n",
    "                                       linewidths=1)\n",
    "                else:\n",
    "                    # Plot FRL results for different k for k-NN\n",
    "                    s = axs[i].plot(d.iloc[2:, col_i], d.iloc[2:, 0], marker='.', markersize=3, label=names[j],\n",
    "                                    linewidth=1)\n",
    "                    # Plot + for points where D_u <= 0\n",
    "                    if not d_rd.empty:\n",
    "                        axs[i].scatter(d_rd.iloc[:, col_i], d_rd.iloc[:, 0], s=30, color=s[0].get_color(), marker='+',\n",
    "                                       linewidths=1)\n",
    "            # Set x limit equal to 0 for D_u\n",
    "            if d_u:\n",
    "                axs[i].axis(xmin=0)\n",
    "\n",
    "        axs[i].grid(True, axis='both', color='gainsboro', linewidth=0.5)\n",
    "        axs[i].legend()\n",
    "        axs[i].set_ylabel('Accuracy')\n",
    "        if not d_u:\n",
    "            axs[i].set_xlabel(r'$U$')\n",
    "        else:\n",
    "            axs[i].set_xlabel(r'$D_u$')\n",
    "\n",
    "    if save:\n",
    "        if not d_u:\n",
    "            plt.savefig(f'{g_path}{name}_u.png', bbox_inches='tight', dpi=200, pad_inches=0.02)\n",
    "        else:\n",
    "            plt.savefig(f'{g_path}{name}_du.png', bbox_inches='tight', dpi=200, pad_inches=0.02)\n",
    "    plt.show()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db67d1df-0a0d-44a6-b375-7a939e2f1f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_i(df_list, plot_name, save=True, no_print=False):\n",
    "    \"\"\"\n",
    "        Plot metrics for all dataframes in df\n",
    "\n",
    "        :param df_list: nested list with (1) dataframes with accuracy, D_all, D_u, U, U_n for each pre-processing method\n",
    "        (first row of each dataframe should be the baseline results), (2) names of techniques \n",
    "        and (3) the index of the FRL results (needs to be specified, because first row of FRL contains RL results)\n",
    "        :param plot_name: name of plot\n",
    "        :param save: whether to save the plot or not (default=False)\n",
    "        :param no_print: whether to not print anything or print everything (default=False,\n",
    "        =True when tuning hyperparameters for DT)\n",
    "        :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    if not no_print:\n",
    "        print(plot_name)\n",
    "\n",
    "    plt.rcParams.update(plt.rcParamsDefault)\n",
    "    # plt.rc('font', **{'size': 10})\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12.8, 4.8))\n",
    "    axs[0].grid(True, axis='both', color='gainsboro', linewidth=0.5)\n",
    "    axs[1].grid(True, axis='both', color='gainsboro', linewidth=0.5)\n",
    "\n",
    "    techniques = df_list[0]\n",
    "    t_names = df_list[1]\n",
    "    # If no i_frl is provided set i_frl equal to a non existing index in df_list\n",
    "    if len(df_list) == 2:\n",
    "        i_frl = len(df_list)\n",
    "    else:\n",
    "        i_frl = df_list[2]\n",
    "    d_rds = 0\n",
    "\n",
    "    # Iterate over techniques\n",
    "    for i, t in enumerate(techniques):\n",
    "        if plot_name[:7] == 'frl_knn':\n",
    "            i_frl = i\n",
    "        if i == 0:\n",
    "            # Horizontal line at baseline (no pre-processing) accuracy\n",
    "            axs[0].axhline(y=t.iloc[0, 0], c='k', linestyle='dashed', linewidth=1)\n",
    "            axs[1].axhline(y=t.iloc[0, 0], c='k', linestyle='dashed', linewidth=1)\n",
    "            # x at baseline (no pre-processing) D_u, accuracy & U, accuracy\n",
    "            axs[0].plot(t.iloc[0, 2], t.iloc[0, 0], color='k', label='Baseline', linestyle='dashed', linewidth=1,\n",
    "                        marker='x', markersize=7)\n",
    "            axs[1].plot(t.iloc[0, 3], t.iloc[0, 0], color='k', label='Baseline', linestyle='dashed', linewidth=1,\n",
    "                        marker='x', markersize=7)\n",
    "\n",
    "        # Create dataframe with rows for which reverse discrimination (D_u ≤ 0) occurs\n",
    "        if i != i_frl:\n",
    "            d_rd = t.iloc[1:, :].loc[t['D_u'] <= 0]\n",
    "        else:\n",
    "            d_rd = t.iloc[2:, :].loc[t['D_u'] <= 0]\n",
    "        d_rds += 1\n",
    "        if d_rds == 1:\n",
    "            axs[1].scatter(d_rd.iloc[:, 3], d_rd.iloc[:, 0], s=30, color='k', marker='+', label='$D_u$≤0', linewidths=1)\n",
    "\n",
    "        if i == i_frl:\n",
    "            axs[0].plot(t.iloc[2:, 2], t.iloc[2:, 0], marker='.', markersize=3, label=t_names[i], linewidth=1)\n",
    "            q = axs[1].plot(t.iloc[2:, 3], t.iloc[2:, 0], marker='.', markersize=3, label=t_names[i], linewidth=1)\n",
    "            # Plot + for points where D_u <= 0\n",
    "            axs[1].scatter(d_rd.iloc[:, 3], d_rd.iloc[:, 0], s=30, color=q[0].get_color(), marker='+', linewidths=1)\n",
    "        else:\n",
    "            # Plot 1 point at baseline results for where frw_knn should've been\n",
    "            if t_names[1] != 'FRW' and t_names[1] != 'k=3' and i == 1:\n",
    "                axs[0].plot(t.iloc[0, 2], t.iloc[0, 0])\n",
    "                axs[1].plot(t.iloc[0, 3], t.iloc[0, 0])\n",
    "            # Plot D_u, accuracy & U, accuracy for every technique\n",
    "            axs[0].plot(t.iloc[1:, 2], t.iloc[1:, 0], marker='.', markersize=3, label=t_names[i], linewidth=1)\n",
    "            r = axs[1].plot(t.iloc[1:, 3], t.iloc[1:, 0], marker='.', markersize=3, label=t_names[i], linewidth=1)\n",
    "            # Plot + for points where D_u <= 0\n",
    "            axs[1].scatter(d_rd.iloc[:, 3], d_rd.iloc[:, 0], s=30, color=r[0].get_color(), marker='+', linewidths=1)\n",
    "\n",
    "    # Set x limit equal to 0 for D_u        \n",
    "    axs[0].axis(xmin=0)\n",
    "    axs[0].legend()\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel(r'$D_u$')\n",
    "\n",
    "    axs[1].legend()\n",
    "    axs[1].set_ylabel('Accuracy')\n",
    "    axs[1].set_xlabel(r'$U$')\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(f'{g_path}{plot_name}.png', bbox_inches='tight', dpi=200, pad_inches=0.02)\n",
    "    plt.show()\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea2cbfd4-6c07-49d4-8225-f762a6823429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_ii(df_list, plot_name, save=True, no_print=False):\n",
    "    \"\"\"\n",
    "        Plot metrics for all dataframes in df\n",
    "\n",
    "        :param df_list: nested list with (1) dataframes with accuracy, D_all, D_u, U, U_n for each pre-processing method\n",
    "        (first row of each dataframe should be the baseline results), (2) names of techniques \n",
    "        and (3) the index of the FRL results (needs to be specified, because first row of FRL contains RL results)\n",
    "        :param plot_name: name of plot\n",
    "        :param save: whether to save the plot or not (default=False)\n",
    "        :param no_print: whether to not print anything or print everything (default=False,\n",
    "        =True when tuning hyperparameters for DT)\n",
    "        :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    if not no_print:\n",
    "        print(plot_name)\n",
    "\n",
    "    plt.rcParams.update(plt.rcParamsDefault)\n",
    "    # plt.rc('font', **{'size': 10})\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.grid(True, axis='both', color='gainsboro', linewidth=0.5)\n",
    "\n",
    "    techniques = df_list[0]\n",
    "    t_names = df_list[1]\n",
    "    # If no i_frl is provided set i_frl equal to a non existing index in df_list\n",
    "    if len(df_list) == 2:\n",
    "        i_frl = len(df_list)\n",
    "    else:\n",
    "        i_frl = df_list[2]\n",
    "\n",
    "    # Iterate over techniques\n",
    "    for i, t in enumerate(techniques):\n",
    "        if i == i_frl:\n",
    "            ax.plot(t.iloc[2:, 2], t.iloc[2:, 3], marker='.', markersize=3, label=t_names[i], linewidth=1)\n",
    "        else:\n",
    "            # Plot 1 point at baseline results for where frw_knn should've been\n",
    "            if t_names[1] != 'FRW' and t_names[1] != 'k=3' and i == 1:\n",
    "                ax.plot(t.iloc[0, 2], t.iloc[0, 3])\n",
    "            # Plot D_u, U for every technique\n",
    "            ax.plot(t.iloc[1:, 2], t.iloc[1:, 3], marker='.', markersize=3, label=t_names[i], linewidth=1)\n",
    "\n",
    "    # Set x limit equal to 0 for D_u        \n",
    "    ax.legend()\n",
    "    ax.set_ylabel(r'$U$')\n",
    "    ax.set_xlabel(r'$D_u$')\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(f'{g_path}{plot_name}.png', bbox_inches='tight', dpi=200, pad_inches=0.02)\n",
    "    plt.show()\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76d4d06f-51a9-4aa3-b12b-8953bb1e9241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metrics(file_names, file_path):\n",
    "    \"\"\"\n",
    "        Loads df_metrics from specified path in list\n",
    "\n",
    "        :param file_names: list of file names in path\n",
    "        :param file_path: path of file names\n",
    "        :return: list with df_metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    files = []\n",
    "    for name in file_names:\n",
    "        file = pd.read_excel(f'{file_path}{name}.xlsx', index_col=0)\n",
    "        if file.empty:\n",
    "            print(f'{name} is empty')\n",
    "        files.append(file)\n",
    "    return files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "544e5d23-995c-4e92-bd73-d7daa6008013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rl_metrics(df_metrics, indices):\n",
    "    \"\"\"\n",
    "        Puts RL metrics from FRL df_metrics into one dataframe\n",
    "\n",
    "        :param df_metrics: list with df_metrics from FRL\n",
    "        :param indices: indices indicating the elements in df_metrics\n",
    "        :return: df with RL metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    rl_metrics = pd.DataFrame(index=indices, columns=['Accuracy', 'D_u', 'U'])\n",
    "    for i, df in enumerate(df_metrics):\n",
    "        rl_metrics.loc[indices[i]] = [df.iloc[1, 0], df.iloc[1, 2], df.iloc[1, 3]]\n",
    "    rl_metrics.to_excel(f'{m_path}rl_metrics.xlsx')\n",
    "    return rl_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0175ce1f-6bd5-47ad-a498-bc682eabf244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metrics_table(df_metrics, indices, column_names, n_decimals=3):\n",
    "    \"\"\"\n",
    "        Creates/exports summary table of metrics\n",
    "\n",
    "        :param df_metrics: nested list with df_metrics[j] = classifiers, \n",
    "        df_metrics[j][i] = [technique, optimal hp value for D_u, optimal hp value for U]\n",
    "        :param indices: indices indicating the techniques in df_metrics[j][i]\n",
    "        :param column_names: indices indicating the techniques in df_metrics[j][i]\n",
    "        :param n_decimals: number of decimals to round metrics to\n",
    "        :return: df with metrics for specified hyperparameters for D_u and U\n",
    "    \"\"\"\n",
    "\n",
    "    du_table = pd.DataFrame(index=indices, columns=column_names)\n",
    "    u_table = pd.DataFrame(index=indices, columns=column_names)\n",
    "    if len(df_metrics) != len(column_names):\n",
    "        raise ValueError('The number of classifiers in df_metrics should be equal to the number of '\n",
    "                         'specified column names')\n",
    "    for j, clf in enumerate(df_metrics):\n",
    "        if len(clf) != len(indices):\n",
    "            raise ValueError('The number techniques for each classifier in df_metrics should be equal to the number of '\n",
    "                             'specified indices')\n",
    "        for i, [df, param_du, param_u] in enumerate(clf):\n",
    "            if isinstance(df, list):\n",
    "                df_du = df[0]\n",
    "                df_u = df[1]\n",
    "            else:\n",
    "                df_du = df\n",
    "                df_u = df\n",
    "            if not df_du.empty and not df_u.empty:\n",
    "                du_table.loc[indices[i], column_names[j]] = str(round(df_du.loc[param_du][2], n_decimals)) + ' (' + str(\n",
    "                    round(df_du.loc[param_du][0], n_decimals)) + ')'\n",
    "                u_table.loc[indices[i], column_names[j]] = str(round(df_u.loc[param_u][3], n_decimals)) + ' (' + str(\n",
    "                    round(df_u.loc[param_u][0], n_decimals)) + ')'\n",
    "    du_table.to_excel(f'{m_path}summary_table_du.xlsx')\n",
    "    u_table.to_excel(f'{m_path}summary_table_u.xlsx')\n",
    "    return du_table, u_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5296fe4b-1bb5-470d-9280-114f127a4b9e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Group unfairness prevention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3e860ca-39a0-4252-a2f7-8eed868699d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rates(df):\n",
    "    \"\"\"\n",
    "        Compute FNR & FPR\n",
    "\n",
    "        :param df: dataframe with y_prob, y_true, s, e\n",
    "        :return: FNR, FPR\n",
    "    \"\"\"\n",
    "    \n",
    "    y_prob = df.drop(['y_true', 's', 'e'], axis=1).columns[0]\n",
    "    tn, fp, fn, tp = confusion_matrix(df['y_true'], df[y_prob]).ravel()\n",
    "    fnr = fn / (fn + tp)\n",
    "    fpr = fp / (fp + tn)\n",
    "    return fnr, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d095f7a8-4e3f-4761-9b42-3cc51c762fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_misclassification_metrics(df_copy):\n",
    "    \"\"\"\n",
    "        Calculate FNR's/FPR's for deprived/favored group \n",
    "        \n",
    "        :param df_copy: dataframe with y_prob, y_true, s, e\n",
    "        :return: FNR's/FPR's and their indices for deprived/favored group\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df_copy.copy()\n",
    "    y_prob = df.drop(['y_true', 's', 'e'], axis=1).columns[0]\n",
    "    \n",
    "    # Rounding down    \n",
    "    df[y_prob] = (df[y_prob] > 0.5).astype(int)\n",
    "    df_f = df[df['s'] != 1]\n",
    "    df_d = df[df['s'] == 1]    \n",
    "\n",
    "    fnr_d, fpr_d = get_rates(df_d)\n",
    "    fnr_f, fpr_f = get_rates(df_f)\n",
    "\n",
    "    d_ix = df[(df['s'] == 1) & (df['y_true'] == 1) & (df[y_prob] == 0)].index\n",
    "    f_ix = df[(df['s'] == 0) & (df['y_true'] == 0) & (df[y_prob] == 1)].index\n",
    "\n",
    "    return fnr_d, fpr_d, fnr_f, fpr_f, d_ix, f_ix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fee166f-c780-4fa6-85e2-a1f95d7b7334",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load datasets + define sensitive/explanatory attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1fe30e-ba90-438b-a0be-5bd79330a9fe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31a2d914-3c9a-49bf-a7e7-cc4986dcd452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy_example_data = [[1, 'medicine', 1], [1, 'medicine', 0], [1, 'computer', 1],\n",
    "#                     [1, 'computer', 0], [0, 'medicine', 1], [0, 'medicine', 0],\n",
    "#                     [0, 'computer', 1], [0, 'computer', 0]]\n",
    "# df_toy_example = pd.DataFrame(toy_example_data, columns=['gender', 'program', 'accepted'])\n",
    "# # print(df_toy_example)\n",
    "# # Female, accepted, medicine\n",
    "# df_toy_example_01 = df_toy_example.loc[pd.Index([0]).repeat(120)]\n",
    "# # Female, rejected, medicine\n",
    "# df_toy_example_01 = pd.concat([df_toy_example_01, df_toy_example.loc[pd.Index([1]).repeat(680)]])\n",
    "# # Female, accepted, computer\n",
    "# df_toy_example_01 = pd.concat([df_toy_example_01, df_toy_example.loc[pd.Index([2]).repeat(90)]])\n",
    "# # Female, rejected, computer\n",
    "# df_toy_example_01 = pd.concat([df_toy_example_01, df_toy_example.loc[pd.Index([3]).repeat(110)]])\n",
    "# # Male, accepted, medicine\n",
    "# df_toy_example_01 = pd.concat([df_toy_example_01, df_toy_example.loc[pd.Index([4]).repeat(70)]])\n",
    "# # Male, rejected, medicine\n",
    "# df_toy_example_01 = pd.concat([df_toy_example_01, df_toy_example.loc[pd.Index([5]).repeat(130)]])\n",
    "# # Male, accepted, computer\n",
    "# df_toy_example_01 = pd.concat([df_toy_example_01, df_toy_example.loc[pd.Index([6]).repeat(360)]])\n",
    "# # Male, rejected, computer\n",
    "# df_toy_example_01 = pd.concat([df_toy_example_01, df_toy_example.loc[pd.Index([7]).repeat(440)]])\n",
    "# df_toy_example_01.to_excel(f'Data/toy_example.xlsx')\n",
    "# d_all_toy = get_d_all(df_toy_example_01, 'gender', 'accepted')\n",
    "# d_unfair_i_toy = get_d_unfair_i(df_toy_example_01, ['program'], n_bins=[2], name='toy')\n",
    "# d_unfair_toy = get_d_unfair(df_toy_example_01, d_all_toy, ['program'], n_bins=[2], print_vc=1, export=1, name='toy')\n",
    "# print()\n",
    "# print(d_all_toy)\n",
    "# print(round(d_unfair_toy, 4))\n",
    "# print(round(d_unfair_i_toy, 4))\n",
    "# print(round(d_unfair_i_toy - d_unfair_toy, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae899db-3fc2-4b75-a8b5-e09a716d706a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7b42596-741c-41e9-b1fc-7df22a94da21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sim_n_expl = pd.read_excel(f'Code outputs/simulated_data_non_expl.xlsx')\n",
    "# df_sim_expl = pd.read_excel('Code outputs/simulated_data_expl.xlsx')\n",
    "# plot_histograms(df_sim_n_expl, 'redline', [])\n",
    "# plot_histograms(df_sim_expl, 'workinghours', [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f0a273-8018-4c47-ba4b-fb142081757f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### German Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d771379-8876-40ad-a997-82bf94c59f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_german = pd.read_csv(f'Data/German Credit/german.csv', delim_whitespace=True, header=None)\n",
    "# df_german.columns = ['checking_status', 'duration', 'credit_history', 'purpose', 'credit_amount', 'savings_status',\n",
    "#                      'employment', 'installment_commitment', 'personal_status', 'other_parties', 'residence_since',\n",
    "#                      'property_magnitude', 'age', 'other_payment_plans', 'housing', 'existing_credits', 'job',\n",
    "#                      'num_dependents', 'own_telephone', 'foreign_worker', 'class']\n",
    "# df_german = remove_whitespace(df_german)\n",
    "# df_german.replace('?', np.nan, inplace=True)\n",
    "# df_german = drop_constant_cols(df_german)\n",
    "# df_german = df_german.dropna().reset_index(drop=True)\n",
    "\n",
    "# df_german['class'] = (df_german['class'] == 1).astype(int)\n",
    "# df_german['personal_status'] = (\n",
    "#             (df_german['personal_status'] == 'A92') | (df_german['personal_status'] == 'A95')).astype(int)\n",
    "# print_df_info(df_german)\n",
    "# d_all_german = get_d_all(df_german, 'personal_status', 'class')\n",
    "# print(f'D_all = {round(d_all_german, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0941954d-2433-4dc7-babe-9fe373382915",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37dc1c34-fab2-41b4-a106-b09ff3a2cb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped constant columns: []\n",
      "\n",
      "Shape of df: (45222, 13)\n",
      "Percentage of duplicate rows: 0.1323\n",
      "Percentage of duplicate rows (attributes only): 0.1546\n",
      "\n",
      "Value count for sex:\n",
      "sex\n",
      "0    30527\n",
      "1    14695\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage for sex:\n",
      "sex\n",
      "0    0.675\n",
      "1    0.325\n",
      "Name: proportion, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_adult_train = pd.read_csv(f'Data/Adult/adult.csv', header=None)\n",
    "df_adult_test = pd.read_csv(f'Data/Adult/adult_test.csv', skiprows=[0], header=None)\n",
    "df_adult = pd.concat([df_adult_train, df_adult_test], ignore_index=True)\n",
    "df_adult.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation',\n",
    "                    'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
    "                    'income']\n",
    "\n",
    "df_adult = remove_whitespace(df_adult)\n",
    "df_adult.replace('?', np.nan, inplace=True)\n",
    "df_adult = drop_constant_cols(df_adult)\n",
    "df_adult = df_adult.drop(['fnlwgt', 'education'], axis=1)\n",
    "\n",
    "df_adult['income'] = df_adult['income'].map({'<=50K': '0', '>50K': '1', '<=50K.': '0', '>50K.': '1'}).astype('int64')\n",
    "df_adult['sex'] = df_adult['sex'].map({'Male': 0, 'Female': 1})\n",
    "\n",
    "df_adult = df_adult.dropna().reset_index(drop=True)\n",
    "\n",
    "class_label = df_adult.pop('income')\n",
    "df_adult.insert(0, 'income', class_label)\n",
    "sensitive_attribute = df_adult.pop('sex')\n",
    "df_adult.insert(1, 'sex', sensitive_attribute)\n",
    "explanatory_attribute = df_adult.pop('hours-per-week')\n",
    "df_adult.insert(2, 'hours-per-week', explanatory_attribute)\n",
    "\n",
    "print_df_info(df_adult)\n",
    "\n",
    "# The sensitive attribute is not used in the distance function and does not have to be one-hot encoded\n",
    "# and therefore should also not be included in any of the 4 _cols_ lists below\n",
    "# Better to specify column names instead of indices in a list, because indices might change\n",
    "bin_cols_adult = []\n",
    "nom_cols_adult = ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'native-country']\n",
    "int_cols_adult = ['hours-per-week', 'age', 'capital-gain', 'capital-loss']\n",
    "ord_cols_adult = ['education-num']\n",
    "cat_cols_adult = ['workclass', 'education-num', 'marital-status', 'occupation', 'relationship', 'race',\n",
    "                  'sex', 'native-country']\n",
    "\n",
    "# Ordinal encode all alphabetic columns\n",
    "df_adult = ordinal_encode(df_adult,\n",
    "                          ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'native-country'])\n",
    "\n",
    "d_all_adult = get_d_all(df_adult)\n",
    "\n",
    "df_adult_original = df_adult.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "647c916a-fc5d-4d03-9a62-9156d32e77b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = get_d_unfair(df_adult, d_all_adult, cat_cols_adult, list(df_adult.drop(['income', 'sex'], axis=1).columns),\n",
    "#                  n_bins=[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 30, 40, 50, 60, 70], export=1,\n",
    "#                  name='adult')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2dbc3b1f-2da0-4496-9f92-eaba693358fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value count for hours-per-week (discretized):\n",
      "hours-per-week\n",
      "9      198\n",
      "8      287\n",
      "7      648\n",
      "0      777\n",
      "5     1527\n",
      "6     2541\n",
      "1     2825\n",
      "2     2933\n",
      "4     8576\n",
      "3    24910\n",
      "Name: count, dtype: int64\n",
      "\n",
      "D_all = 0.1989\n",
      "D_unfair = 0.1531\n"
     ]
    }
   ],
   "source": [
    "# D_unfair for hours-per-week should be around 14.16%\n",
    "d_unfair_adult = get_d_unfair(df_adult, d_all_adult, cat_cols_adult, ['hours-per-week'], print_vc=1,\n",
    "                              name='adult')\n",
    "print(f'D_all = {round(d_all_adult, 4)}')\n",
    "print(f'D_unfair = {round(d_unfair_adult, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87b98959-24e3-41d6-9e8d-8a681052ae71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_all = 0.1989\n",
      "D_unfair = 0.0269\n"
     ]
    }
   ],
   "source": [
    "d_unfair_adult = get_d_unfair(df_adult, d_all_adult, cat_cols_adult, ['marital-status'], n_bins=[10], print_vc=1,\n",
    "                              name='adult')\n",
    "print(f'D_all = {round(d_all_adult, 4)}')\n",
    "print(f'D_unfair = {round(d_unfair_adult, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "267f8cfd-5324-4a60-b5bb-6a7d91def909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_adult_original.to_excel(f'Code outputs/df_adult_original.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e1f9dff-7872-4409-b81f-f2eaf0190c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in list(df_adult_original.columns[2:]):\n",
    "#     plot_histograms(df_adult_original, column, cat_cols_adult)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22739109-f5e7-46ed-b22b-1925fa462648",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Communities and Crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48d6107c-164a-4ae9-97f8-6782b7e639d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_cac = pd.read_csv(f'Data/Communities and Crime/communities.csv', header=None)\n",
    "# df_cac.columns = ['state', 'county', 'community', 'communityname', 'fold', 'population', 'householdsize',\n",
    "#                   'racepctblack', 'racePctWhite', 'racePctAsian', 'racePctHisp', 'agePct12t21', 'agePct12t29',\n",
    "#                   'agePct16t24', 'agePct65up', 'numbUrban', 'pctUrban', 'medIncome', 'pctWWage', 'pctWFarmSelf',\n",
    "#                   'pctWInvInc', 'pctWSocSec', 'pctWPubAsst', 'pctWRetire', 'medFamInc', 'perCapInc', 'whitePerCap',\n",
    "#                   'blackPerCap', 'indianPerCap', 'AsianPerCap', 'OtherPerCap', 'HispPerCap', 'NumUnderPov',\n",
    "#                   'PctPopUnderPov', 'PctLess9thGrade', 'PctNotHSGrad', 'PctBSorMore', 'PctUnemployed', 'PctEmploy',\n",
    "#                   'PctEmplManu', 'PctEmplProfServ', 'PctOccupManu', 'PctOccupMgmtProf', 'MalePctDivorce',\n",
    "#                   'MalePctNevMarr', 'FemalePctDiv', 'TotalPctDiv', 'PersPerFam', 'PctFam2Par', 'PctKids2Par',\n",
    "#                   'PctYoungKids2Par', 'PctTeen2Par', 'PctWorkMomYoungKids', 'PctWorkMom', 'NumIlleg', 'PctIlleg',\n",
    "#                   'NumImmig', 'PctImmigRecent', 'PctImmigRec5', 'PctImmigRec8', 'PctImmigRec10', 'PctRecentImmig',\n",
    "#                   'PctRecImmig5', 'PctRecImmig8', 'PctRecImmig10', 'PctSpeakEnglOnly', 'PctNotSpeakEnglWell',\n",
    "#                   'PctLargHouseFam', 'PctLargHouseOccup', 'PersPerOccupHous', 'PersPerOwnOccHous', 'PersPerRentOccHous',\n",
    "#                   'PctPersOwnOccup', 'PctPersDenseHous', 'PctHousLess3BR', 'MedNumBR', 'HousVacant', 'PctHousOccup',\n",
    "#                   'PctHousOwnOcc', 'PctVacantBoarded', 'PctVacMore6Mos', 'MedYrHousBuilt', 'PctHousNoPhone',\n",
    "#                   'PctWOFullPlumb', 'OwnOccLowQuart', 'OwnOccMedVal', 'OwnOccHiQuart', 'RentLowQ', 'RentMedian',\n",
    "#                   'RentHighQ', 'MedRent', 'MedRentPctHousInc', 'MedOwnCostPctInc', 'MedOwnCostPctIncNoMtg',\n",
    "#                   'NumInShelters', 'NumStreet', 'PctForeignBorn', 'PctBornSameState', 'PctSameHouse85', 'PctSameCity85',\n",
    "#                   'PctSameState85', 'LemasSwornFT', 'LemasSwFTPerPop', 'LemasSwFTFieldOps', 'LemasSwFTFieldPerPop',\n",
    "#                   'LemasTotalReq', 'LemasTotReqPerPop', 'PolicReqPerOffic', 'PolicPerPop', 'RacialMatchCommPol',\n",
    "#                   'PctPolicWhite', 'PctPolicBlack', 'PctPolicHisp', 'PctPolicAsian', 'PctPolicMinor',\n",
    "#                   'OfficAssgnDrugUnits', 'NumKindsDrugsSeiz', 'PolicAveOTWorked', 'LandArea', 'PopDens',\n",
    "#                   'PctUsePubTrans', 'PolicCars', 'PolicOperBudg', 'LemasPctPolicOnPatr', 'LemasGangUnitDeploy',\n",
    "#                   'LemasPctOfficDrugUn', 'PolicBudgPerPop', 'ViolentCrimesPerPop']\n",
    "# df_cac = remove_whitespace(df_cac)\n",
    "# df_cac.replace('?', np.nan, inplace=True)\n",
    "# df_cac = drop_constant_cols(df_cac)\n",
    "# # Drop all 5 non-predictive attributes\n",
    "# df_cac = df_cac.drop(['state', 'county', 'community', 'communityname', 'fold'], axis=1)\n",
    "# df_cac = df_cac.dropna().reset_index(drop=True)\n",
    "# df_cac = df_cac.apply(pd.to_numeric)\n",
    "\n",
    "# df_cac['Black'] = (df_cac['racepctblack'] > 0.06).astype(int)\n",
    "# df_cac['ViolentCrimesPerPop-d'] = (df_cac['ViolentCrimesPerPop'] <= 0.2).astype(int)\n",
    "# df_cac = df_cac[df_cac['Black'].notna()]\n",
    "# print_df_info(df_cac)\n",
    "\n",
    "# class_label = df_cac.pop('ViolentCrimesPerPop-d')\n",
    "# df_cac.insert(0, 'ViolentCrimesPerPop-d', class_label)\n",
    "# sensitive_attribute = df_cac.pop('Black')\n",
    "# df_cac.insert(1, 'Black', sensitive_attribute)\n",
    "# cat_cols_cac = []\n",
    "\n",
    "# d_all_cac = get_d_all(df_cac)\n",
    "# # logit(d_all_cac, 'cac', ['ViolentCrimesPerPop-d', 'Black'])\n",
    "# # df_cac.corr(method='kendall')[['Black', 'ViolentCrimesPerPop-d']].abs().sort_values('Black', ascending=False).to_excel(\n",
    "# #     f'{path}cac_correlations.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a99bcdb-ef83-4b5f-b753-93db85998ecc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Explanatory attributes candidates: PctKids2Par, PctIlleg, TotalPctDiv, NumUnderPov, population\n",
    "# # D_unfair for PctKids2Par should be around 23.47%\n",
    "# d_unfair_cac = get_d_unfair(df_cac, d_all_cac, cat_cols_cac, ['PctKids2Par'], n_bins=[2], print_vc=1, name='cac')\n",
    "# print(f'D_all = {round(d_all_cac, 4)}')\n",
    "# print(f'D_unfair = {round(d_unfair_cac.iloc[0, 0], 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e92839-ea88-443c-b4a9-56c0b0213a10",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Bank Marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "caae7917-298f-4f78-8ef7-f237efd28d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_bank = pd.read_csv(f'Data/Bank Marketing/bank-full.csv', delimiter=';')\n",
    "# df_bank = remove_whitespace(df_bank)\n",
    "# df_bank.replace('unknown', np.nan, inplace=True)\n",
    "# df_bank = drop_constant_cols(df_bank)\n",
    "# # Why are these columns dropped?\n",
    "# df_bank.drop(['contact', 'poutcome'], axis=1, inplace=True)\n",
    "# df_bank = df_bank.dropna().reset_index(drop=True)\n",
    "\n",
    "# # Deprived group = people between 25 and 60 years old\n",
    "# df_bank['age_s'] = ((df_bank['age'] >= 25) & (df_bank['age'] <= 60)).astype(int)\n",
    "# print_df_info(df_bank)\n",
    "# df_bank['y'] = df_bank['y'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# class_label = df_bank.pop('y')\n",
    "# df_bank.insert(0, 'y', class_label)\n",
    "# sensitive_attribute = df_bank.pop('age_s')\n",
    "# df_bank.insert(1, 'age_s', sensitive_attribute)\n",
    "# cat_cols_bank = ['age_s', 'job', 'marital', 'education', 'default', 'housing', 'loan', 'day', 'month']\n",
    "\n",
    "# d_all_bank = get_d_all(df_bank)\n",
    "\n",
    "# # df_bank_le = df_bank.copy()\n",
    "# # Ordinal attributes need to be label encoded, to compute the correlation matrix\n",
    "# # df_bank_le['education'] = df_bank_le['education'].map({'primary': 0, 'secondary': 1, 'tertiary': 2, 'unknown': np.nan})\n",
    "# # df_bank_le['month'] = df_bank_le['month'].map(\n",
    "# #     {'jan': 0, 'feb': 1, 'mar': 2, 'apr': 3, 'may': 4, 'jun': 5, 'jul': 6, 'aug': 7, 'sep': 8, 'oct': 9, 'nov': 10,\n",
    "# #      'dec': 11})\n",
    "\n",
    "# # logit(df_bank_le, 'bank', ['y', 'age_s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c84628c-0872-4a2b-984d-0e19d57b7c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = get_d_unfair(df_bank, d_all_bank, cat_cols_bank, list(df_bank.drop(['age_s', 'y', 'age'], axis=1).columns),\n",
    "#                  n_bins=[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 30, 40, 50, 60, 70], name='bank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39ff3cac-3c00-4346-b515-58bee561f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_unfair_bank = get_d_unfair(df_bank, d_all_bank, cat_cols_bank, ['month'], n_bins=[2], print_vc=1, name='bank')\n",
    "# print(f'D_all = {round(d_all_bank, 4)}')\n",
    "# print(f'D_unfair = {round(d_unfair_bank, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bebbc90-bed1-41da-abe1-cf012926be7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### COMPAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c19e14c-f3c2-4d14-8c01-f6333d4a8f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped constant columns: ['num_r_cases', 'num_vr_cases', 'v_type_of_assessment', 'type_of_assessment']\n",
      "\n",
      "Shape of df: (8946, 14)\n",
      "Percentage of duplicate rows: 0.1954\n",
      "Percentage of duplicate rows (attributes only): 0.2458\n",
      "\n",
      "Value count for race:\n",
      "race\n",
      "1    5250\n",
      "0    3696\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage for race:\n",
      "race\n",
      "1    0.5869\n",
      "0    0.4131\n",
      "Name: proportion, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_compas = pd.read_csv(f'Data/compas-analysis-master/compas-analysis-master/compas-scores.csv')\n",
    "df_compas = df_compas[(df_compas['race'] == 'African-American') | (df_compas['race'] == 'Caucasian')]\n",
    "df_compas.replace('N/A', np.nan, inplace=True)\n",
    "\n",
    "df_compas = df_compas[df_compas['score_text'].notna()]\n",
    "df_compas['score_text-d'] = (df_compas['score_text'] == 'Low').astype(int)\n",
    "\n",
    "df_compas['race'] = df_compas['race'].map({'Caucasian': 0, 'African-American': 1})\n",
    "df_compas['age_cat'] = df_compas['age_cat'].map({'Less than 25': 0, '25 - 45': 1, 'Greater than 45': 2})\n",
    "# O=ordinary, M=misdemeanor, or F=felony traffic offenses\n",
    "df_compas['c_charge_degree'] = df_compas['c_charge_degree'].map({'O': 0, 'M': 1, 'F': 2})\n",
    "df_compas['r_charge_degree'] = df_compas['r_charge_degree'].map({'O': 0, 'M': 1, 'F': 2})\n",
    "df_compas['vr_charge_degree'] = df_compas['vr_charge_degree'].map(\n",
    "    {'(MO3)': 0, '(M2)': 1, '(M1)': 2, '(F7)': 3, '(F6)': 4, '(F5)': 5, '(F3)': 6, '(F2)': 7, '(F1)': 8})\n",
    "df_compas['v_score_text'] = df_compas['v_score_text'].map({'Low': 0, 'Medium': 1, 'High': 2})\n",
    "df_compas['score_text'] = df_compas['score_text'].map({'Low': 0, 'Medium': 1, 'High': 2})\n",
    "\n",
    "df_compas = drop_constant_cols(df_compas)\n",
    "# Attributes below should not explain score_text, are highly correlated with score_text \n",
    "# (e.g. COMPAS scores), contain mostly empty values or are charge descriptions \n",
    "# (string columns will increase the dimensionality significantly because they have to be one-hot-encoded)\n",
    "df_compas = df_compas.drop(\n",
    "    ['id', 'name', 'first', 'last', 'compas_screening_date', 'dob', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
    "     'c_offense_date', 'c_arrest_date', 'r_case_number', 'r_offense_date', 'r_jail_in', 'r_jail_out', 'vr_case_number',\n",
    "     'vr_offense_date', 'v_screening_date', 'screening_date', 'age_cat', 'decile_score', 'v_decile_score',\n",
    "     'v_score_text', 'decile_score.1', 'score_text', 'r_days_from_arrest', 'vr_charge_degree', 'c_charge_desc',\n",
    "     'r_charge_desc', 'vr_charge_desc'], axis=1)\n",
    "\n",
    "df_compas = df_compas.dropna().reset_index(drop=True)\n",
    "\n",
    "class_label = df_compas.pop('score_text-d')\n",
    "df_compas.insert(0, 'score_text-d', class_label)\n",
    "sensitive_attribute = df_compas.pop('race')\n",
    "df_compas.insert(1, 'race', sensitive_attribute)\n",
    "explanatory_attribute = df_compas.pop('priors_count')\n",
    "df_compas.insert(2, 'priors_count', explanatory_attribute)\n",
    "\n",
    "print_df_info(df_compas)\n",
    "\n",
    "bin_cols_compas = ['is_recid', 'is_violent_recid', 'sex']\n",
    "nom_cols_compas = []\n",
    "int_cols_compas = ['age', 'juv_fel_count', 'juv_misd_count', 'juv_other_count', 'priors_count',\n",
    "                   'days_b_screening_arrest', 'c_days_from_compas']\n",
    "ord_cols_compas = ['c_charge_degree', 'r_charge_degree']\n",
    "\n",
    "cat_cols_compas = ['race', 'c_charge_degree', 'is_recid', 'r_charge_degree', 'is_violent_recid', 'sex']\n",
    "\n",
    "# Ordinal encode all alphabetic columns\n",
    "df_compas = ordinal_encode(df_compas, ['sex'])\n",
    "\n",
    "d_all_compas = get_d_all(df_compas)\n",
    "\n",
    "df_compas_original = df_compas.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2cd19cc-5bda-4bea-b2fa-78c190a37655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = get_d_unfair(df_compas, d_all_compas, cat_cols_compas,\n",
    "#                  list(df_compas.drop(['race', 'score_text-d'], axis=1).columns),\n",
    "#                  n_bins=[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 30, 40, 50, 60, 70], export=1,\n",
    "#                  name='compas')\n",
    "# _ = get_d_unfair_i(df_compas, list(df_compas.drop(['race', 'score_text-d'], axis=1).columns),\n",
    "#                    n_bins=[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 30, 40, 50, 60, 70], name='compas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8109d8c3-9109-4fc5-aff1-bf4167c908ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value count for priors_count (discretized):\n",
      "priors_count\n",
      "5       6\n",
      "4      18\n",
      "3     102\n",
      "2     294\n",
      "1     939\n",
      "0    7587\n",
      "Name: count, dtype: int64\n",
      "\n",
      "D_all = 0.243\n",
      "D_unfair = 0.1937\n"
     ]
    }
   ],
   "source": [
    "d_unfair_compas = get_d_unfair(df_compas, d_all_compas, cat_cols_compas, ['priors_count'], n_bins=[6], print_vc=1,\n",
    "                               name='compas')\n",
    "print(f'D_all = {round(d_all_compas, 4)}')\n",
    "print(f'D_unfair = {round(d_unfair_compas, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a18994c-ff17-453f-994f-14aab8d9beb6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### AdviceRobo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cac8991b-796b-4d5c-80f3-4f62eec51c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped constant columns: ['is_test', 'arrears', 'version', 'confidence', 'skills', 'ageStep', 'ageIndex', 'F003', 'F003Duration', 'F003Step', 'F003Index', 'F003PostedAt', 'F004', 'F004Duration', 'F004Step', 'F004Index', 'F004PostedAt', 'O001', 'O001Duration', 'O001Step', 'O001Index', 'O001PostedAt', 'O005', 'O005Duration', 'O005Step', 'O005Index', 'O005PostedAt', 'start', 'startStep', 'startIndex', 'ZZZ002Step', 'Country']\n",
      "\n",
      "Shape of df: (2887, 35)\n",
      "Percentage of duplicate rows: 0.0\n",
      "Percentage of duplicate rows (attributes only): 0.0\n",
      "\n",
      "Value count for lang:\n",
      "lang\n",
      "0    2419\n",
      "1     468\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage for lang:\n",
      "lang\n",
      "0    0.8379\n",
      "1    0.1621\n",
      "Name: proportion, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ar_pcs = pd.read_excel(f'Data/AdviceRobo/2022_Cashbot_psychoscoring.xlsx')\n",
    "df_ar_full = pd.read_excel(f'Data/AdviceRobo/cashbot_full_data kopie.xlsx')\n",
    "df_ar_merged = pd.read_excel(f'Data/AdviceRobo/merged_dataset.xlsx')\n",
    "df_ar_pcs['ApplicatintID'] = df_ar_pcs['ApplicatintID'].str.replace('-', '').str.lower()\n",
    "df_ar = df_ar_pcs.merge(df_ar_full, left_on='ApplicatintID', right_on='applicant_external_id')\n",
    "df_ar = df_ar.merge(df_ar_merged, left_on='ApplicatintID', right_on='applicant_external_id', suffixes=('_cb', '_ar'))\n",
    "# Drop all identical columns\n",
    "df_ar_copy = df_ar.copy()\n",
    "for clmn in df_ar_copy:\n",
    "    if clmn[-2:] == 'cb':\n",
    "        column = clmn[:len(clmn) - 2] + 'ar'\n",
    "        if df_ar_copy[clmn].equals(df_ar_copy[column]):\n",
    "            df_ar = df_ar.drop([clmn], axis=1)\n",
    "            df_ar.rename(columns={column: column[:len(column) - 3]}, inplace=True)\n",
    "df_ar = drop_constant_cols(df_ar)\n",
    "\n",
    "# Drop ApplicatintID/questionnaire_session_id/applicant_id (same as applicant_external_id)\n",
    "# Psycho_score (same as pcs_score), startDuration_cb/startDuration_ar (91% is empty)\n",
    "df_ar = df_ar.drop(['ApplicatintID', 'questionnaire_session_id', 'applicant_id', 'startDuration_cb', 'startDuration_ar',\n",
    "                    'Psycho_score'], axis=1)\n",
    "\n",
    "# Drop Unprocessed rows\n",
    "df_ar = df_ar.loc[df_ar['Entity_status'].isin(['Rejected', 'Verified'])]\n",
    "\n",
    "# Drop duplicate rows\n",
    "df_ar = df_ar.drop_duplicates(subset=df_ar.columns.difference(['startPostedAt_cb']))\n",
    "\n",
    "df_ar['Entity_status'] = (df_ar['Entity_status'] == 'Verified').astype(int)\n",
    "# Deprived group = Slovak, favored group = Czech\n",
    "df_ar['lang'] = (df_ar['lang'] == 'sk').astype(int)\n",
    "\n",
    "# Select variables in correct order\n",
    "df_ar = df_ar[\n",
    "    ['Entity_status', 'lang', 'gratification', 'pcs_score', 'is_too_fast', 'is_team_work', 'debtAttitude',\n",
    "     'knowledgeSkills', 'materialism', 'reasoning', 'selfEfficacy', 'socialDesirability', 'age', 'N001', 'N002', 'N003',\n",
    "     'O002', 'O003', 'O004', 'P001', 'P002', 'P003', 'Q001', 'Q002', 'Q003', 'R001', 'R002', 'R003', 'S001', 'S002',\n",
    "     'S003', 'T003', 'T004', 'ZZZ002', 'Entity_type']]\n",
    "\n",
    "df_ar = df_ar.dropna().reset_index(drop=True)\n",
    "\n",
    "print_df_info(df_ar)\n",
    "\n",
    "bin_cols_ar = ['is_too_fast', 'is_team_work', 'N001', 'N002', 'N003', 'Entity_type']\n",
    "nom_cols_ar = ['T003', 'T004']\n",
    "int_cols_ar = ['pcs_score', 'age']\n",
    "ord_cols_ar = ['gratification', 'debtAttitude', 'knowledgeSkills', 'materialism', 'reasoning', 'selfEfficacy',\n",
    "               'socialDesirability', 'O002', 'O003', 'O004', 'P001', 'P002', 'P003', 'Q001', 'Q002', 'Q003', 'R001',\n",
    "               'R002', 'R003', 'S001', 'S002', 'S003', 'ZZZ002']\n",
    "\n",
    "cat_cols_ar = ['lang', 'gratification', 'is_too_fast', 'is_team_work', 'debtAttitude', 'knowledgeSkills', 'materialism',\n",
    "               'reasoning', 'selfEfficacy', 'socialDesirability', 'N001', 'N002', 'N003', 'O002', 'O003', 'O004',\n",
    "               'P001', 'P002', 'P003', 'Q001', 'Q002', 'Q003', 'R001', 'R002', 'R003', 'S001', 'S002', 'S003', 'T003',\n",
    "               'T004', 'ZZZ002', 'Entity_type']\n",
    "\n",
    "# Ordinal encode all alphabetic columns\n",
    "df_ar = ordinal_encode(df_ar,\n",
    "                       ['N001', 'N002', 'N003', 'O002', 'O003', 'O004', 'P001', 'P002', 'P003', 'Q001', 'Q002', 'Q003',\n",
    "                        'R001', 'R002', 'R003', 'S001', 'S002', 'S003', 'T003', 'T004', 'ZZZ002', 'Entity_type'])\n",
    "\n",
    "df_ar_original = df_ar.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eed6b0b2-a8d7-4627-a793-115d5dc1bfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(df_ar.loc[:, ~df_ar.columns.astype(str).str.contains('id|posted_at|Duration|Step|Index|PostedAt')].columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b39afc3-c023-4a75-81ad-1d9cb64ed3d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Try age as sensitive attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19cf91b2-adb6-440e-a25c-7c45e282a69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_alls_ar = np.empty(shape=(0, 2))\n",
    "# for i in range(19, 77):\n",
    "#     df_ar['age_s'] = (df_ar['age'] < i).astype(int)\n",
    "#     d_alls_ar = np.vstack(\n",
    "#         (d_alls_ar, [get_d_all(df_ar, 'age_s', 'Entity_status'), df_ar['age_s'].value_counts(normalize=True)[1]]))\n",
    "# pd.DataFrame(d_alls_ar, index=range(19, 77), columns=['D_all', 'size']).to_excel(f'{path}ar_d_alls.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6f44af02-2593-4380-bde0-7c8aa8fc5477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Favored group = people between 27 and 74 years old\n",
    "# df_ar['age_s'] = ((df_ar['age'] < 27) | (df_ar['age'] > 74)).astype(int)\n",
    "# # print_df_info(df_ar)\n",
    "# d_all_ar = get_d_all(df_ar, 'age_s', 'Entity_status')\n",
    "# # print(f'D_all = {round(d_all_ar, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd28dbc-e6d2-4c5f-afca-c61697013e31",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Continue with language as sensitive attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "715e7e65-fe89-44c5-b521-a6dea11c77e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df: (2887, 35)\n",
      "Percentage of duplicate rows: 0.0\n",
      "Percentage of duplicate rows (attributes only): 0.0\n",
      "\n",
      "Value count for lang:\n",
      "lang\n",
      "0    2419\n",
      "1     468\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage for lang:\n",
      "lang\n",
      "0    0.8379\n",
      "1    0.1621\n",
      "Name: proportion, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_df_info(df_ar)\n",
    "d_all_ar = get_d_all(df_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "874015b0-3247-4990-b7dc-9018b4a7eb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = get_d_unfair(df_ar, d_all_ar, cat_cols_ar, list(df_ar.drop(['Entity_status', 'lang'], axis=1).columns),\n",
    "#                  n_bins=[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 30, 40, 50, 60, 70], export=1, name='ar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3068181a-c175-4b6e-982a-5702ee9a509f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_all = 0.1808\n",
      "D_unfair = 0.1486\n"
     ]
    }
   ],
   "source": [
    "d_unfair_ar = get_d_unfair(df_ar, d_all_ar, cat_cols_ar, ['gratification'], print_vc=1, name='ar')\n",
    "print(f'D_all = {round(d_all_ar, 4)}')\n",
    "print(f'D_unfair = {round(d_unfair_ar, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b03815c-68e9-451a-b73b-a1432cb1c945",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Individual fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb66df2-171c-4d2f-b97f-bda97643ca81",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Optimize weights functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc34faf1-1603-4a90-94fb-3ab9e581e777",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def sum_ddw_distances(p, ddw_distances):\n",
    "    \"\"\"\n",
    "        Sum ddw_distances per attribute\n",
    "\n",
    "        :param p: number of attributes\n",
    "        :param ddw_distances: nested list with ddw_distances\n",
    "        :return: gradient\n",
    "        \"\"\"\n",
    "\n",
    "    gradient = []\n",
    "    for i in range(p):\n",
    "        sum_d = 0\n",
    "        for d in range(len(ddw_distances)):\n",
    "            sum_d += ddw_distances[d][i]\n",
    "        gradient.append(sum_d)\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "291b8594-936d-4fdc-81dd-ebbfdac44618",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def get_ddw_distances(data, c, bin_idx, nom_idx, int_idx, ord_idx, cols_range):\n",
    "    \"\"\"\n",
    "        Compute the derivative of the distance for all instances with the same and a different class label in data \n",
    "\n",
    "        :param data: ndarray with data\n",
    "        :param c: array with class labels\n",
    "        :param bin_idx: array with column indices of binary attributes in data\n",
    "        :param nom_idx: array with column indices of nominal attributes in data\n",
    "        :param int_idx: array with column indices of interval-scaled attributes in data\n",
    "        :param ord_idx: array with column indices of ordinal attributes in data\n",
    "        :param cols_range: array with range for each column\n",
    "        :return: two arrays with derivative distances between instances\n",
    "        \"\"\"\n",
    "    \n",
    "    d2_ddw_same_c = []\n",
    "    d2_ddw_diff_c = []\n",
    "\n",
    "    for x in range(0, len(c)):\n",
    "        for y in range(x + 1, len(c)):\n",
    "            d2_ddw = []\n",
    "            for col in range(0, len(data[x])):\n",
    "                if col in bin_idx or (col in nom_idx and data[x][col] == data[y][col]):\n",
    "                    d2_ddw.append((data[x][col] - data[y][col]) ** 2)\n",
    "                if col in nom_idx and data[x][col] != data[y][col]:\n",
    "                    d2_ddw.append(1)\n",
    "                if (col in int_idx) or (col in ord_idx):\n",
    "                    d2_ddw.append(((data[x][col] - data[y][col]) / cols_range[col]) ** 2)\n",
    "            if c[x] == c[y]:\n",
    "                d2_ddw_same_c.append(d2_ddw)\n",
    "            else:\n",
    "                d2_ddw_diff_c.append(d2_ddw)\n",
    "    return np.array(d2_ddw_same_c), np.array(d2_ddw_diff_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60c5c870-648b-43a0-9f08-dd086f94f1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def podani_gradient(w, x_d, x_f, y_d, y_f, bin_idx, nom_idx, int_idx, ord_idx, cols_range, λ):\n",
    "    \"\"\"\n",
    "        Gradient of objective function in minimize_weighted_podani\n",
    "\n",
    "        :param w: array with weights\n",
    "        :param x_d: attributes deprived group\n",
    "        :param x_f: attributes favored group\n",
    "        :param y_d: class labels deprived group\n",
    "        :param y_f: class labels favored group\n",
    "        :param bin_idx: array with column indices of binary attributes in X\n",
    "        :param nom_idx: array with column indices of nominal attributes in X\n",
    "        :param int_idx: array with column indices of interval-scaled attributes in X\n",
    "        :param ord_idx: array with column indices of ordinal attributes in X\n",
    "        :param cols_range: array with range for each column\n",
    "        :param λ: λ to multiply derivative of squared L2 norm with\n",
    "        :return: objective function\n",
    "        \"\"\"\n",
    "\n",
    "    ddw_d2_d_same, ddw_d2_d_diff = get_ddw_distances(x_d, y_d, bin_idx, nom_idx, int_idx, ord_idx, cols_range)\n",
    "    ddw_d2_f_same, ddw_d2_f_diff = get_ddw_distances(x_f, y_f, bin_idx, nom_idx, int_idx, ord_idx, cols_range)\n",
    "\n",
    "    gradient_d_same = (1 / len(ddw_d2_d_same)) * np.array(sum_ddw_distances(len(x_d[0]), ddw_d2_d_same))\n",
    "    gradient_d_diff = (1 / len(ddw_d2_d_diff)) * np.array(sum_ddw_distances(len(x_d[0]), ddw_d2_d_diff))\n",
    "    gradient_f_same = (1 / len(ddw_d2_f_same)) * np.array(sum_ddw_distances(len(x_d[0]), ddw_d2_f_same))\n",
    "    gradient_f_diff = (1 / len(ddw_d2_f_diff)) * np.array(sum_ddw_distances(len(x_d[0]), ddw_d2_f_diff))\n",
    "\n",
    "    gradient = gradient_d_same + gradient_f_same - gradient_d_diff - gradient_f_diff\n",
    "\n",
    "    for i in range(len(w)):\n",
    "        gradient[i] += 2 * λ * w[i]\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "07fe8481-0233-4801-aac3-91a2474b9786",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def get_distances(data, c, w, bin_idx, nom_idx, int_idx, ord_idx, cols_range):\n",
    "    \"\"\"\n",
    "        Compute distance between all instances with the same and a different class label in data\n",
    "\n",
    "        :param data: ndarray with data\n",
    "        :param c: array with class labels\n",
    "        :param w: array with weights\n",
    "        :param bin_idx: array with column indices of binary attributes in data\n",
    "        :param nom_idx: array with column indices of nominal attributes in data\n",
    "        :param int_idx: array with column indices of interval-scaled attributes in data\n",
    "        :param ord_idx: array with column indices of ordinal attributes in data\n",
    "        :param cols_range: array with range for each column\n",
    "        :return: two lists with distances between instances\n",
    "        \"\"\"\n",
    "\n",
    "    d2_diff_c = []\n",
    "    d2_same_c = []\n",
    "    for x in range(0, len(c)):\n",
    "        for y in range(x + 1, len(c)):\n",
    "            d2 = []\n",
    "            for col in range(0, len(data[x])):\n",
    "                if col in bin_idx or (col in nom_idx and data[x][col] == data[y][col]):\n",
    "                    d2.append(w[col] * ((data[x][col] - data[y][col]) ** 2))\n",
    "                if col in nom_idx and data[x][col] != data[y][col]:\n",
    "                    d2.append(w[col])\n",
    "                if (col in int_idx) or (col in ord_idx):\n",
    "                    d2.append(w[col] * (((data[x][col] - data[y][col]) / cols_range[col]) ** 2))\n",
    "            sum_d2 = sum(d2)\n",
    "            if c[x] == c[y]:\n",
    "                d2_same_c.append(sum_d2)\n",
    "            else:\n",
    "                d2_diff_c.append(sum_d2)\n",
    "    return d2_same_c, d2_diff_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f319a892-cac1-4ff4-a9f1-25f24a424852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_weighted_podani(w, x_d, x_f, y_d, y_f, bin_idx, nom_idx, int_idx, ord_idx, cols_range, λ):\n",
    "    \"\"\"\n",
    "        Objective function to minimize in minimize_weighted_podani\n",
    "\n",
    "        :param w: array with weights\n",
    "        :param x_d: attributes deprived group\n",
    "        :param x_f: attributes favored group\n",
    "        :param y_d: class labels deprived group\n",
    "        :param y_f: class labels favored group\n",
    "        :param bin_idx: array with column indices of binary attributes in X\n",
    "        :param nom_idx: array with column indices of nominal attributes in X\n",
    "        :param int_idx: array with column indices of interval-scaled attributes in X\n",
    "        :param ord_idx: array with column indices of ordinal attributes in X\n",
    "        :param cols_range: array with range for each column\n",
    "        :param λ: λ to multiply squared L2 norm with\n",
    "        :return: objective function\n",
    "        \"\"\"\n",
    "\n",
    "    d2_d_same, d2_d_diff = get_distances(x_d, y_d, w, bin_idx, nom_idx, int_idx, ord_idx, cols_range)\n",
    "    d2_f_same, d2_f_diff = get_distances(x_f, y_f, w, bin_idx, nom_idx, int_idx, ord_idx, cols_range)\n",
    "\n",
    "    f_w = sum(d2_d_same) / len(d2_d_same) + sum(d2_f_same) / len(d2_f_same) - sum(d2_d_diff) / len(d2_d_diff) - sum(\n",
    "        d2_f_diff) / len(d2_f_diff)\n",
    "\n",
    "    l2_norm = λ * sum(w ** 2)\n",
    "\n",
    "    return f_w + l2_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6371c2f5-408e-45a3-bc1e-ba2790c34f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w(df_copy, bin_cols, nom_cols, int_cols, ord_cols, name, start_w=np.nan, save=False):\n",
    "    \"\"\"\n",
    "        Get weights by minimizing objective_weighted_podani using the complete dataset. \n",
    "        The values of the weights should be such that instances with the same class label will have a small distance \n",
    "        between each other and instances with different class label will have large distances between each other.\n",
    "\n",
    "        :param df_copy: dataframe (column 0 = class_label (positive decision = 1),\n",
    "        column 1 = sensitive attribute (deprived group = 1))\n",
    "        :param bin_cols: list with column names of binary attributes in df_copy\n",
    "        :param nom_cols: list with column names of nominal attributes in df_copy\n",
    "        :param int_cols: list with column names of interval-scaled attributes in df_copy\n",
    "        :param ord_cols: list with column names of ordinal attributes in df_copy\n",
    "        :param name: name of dataset\n",
    "        :param start_w: starting values for w (default=None)\n",
    "        :param save: whether to save the weights in an Excel file or not (default=False)\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "\n",
    "    global t0\n",
    "\n",
    "    df = df_copy.copy()\n",
    "    df_x = df.iloc[:, 2:]\n",
    "\n",
    "    # Ranges have to be calculated based on whole dataframe for Podani distance\n",
    "    cols_range = (df_x.max() - df_x.min()).to_numpy()\n",
    "\n",
    "    df_d = df[df.iloc[:, 1] == 1]\n",
    "    df_f = df[df.iloc[:, 1] == 0]\n",
    "    x_d = df_d.iloc[:, 2:].to_numpy()\n",
    "    x_f = df_f.iloc[:, 2:].to_numpy()\n",
    "    y_d = df_d.iloc[:, 0].to_numpy()\n",
    "    y_f = df_f.iloc[:, 0].to_numpy()\n",
    "\n",
    "    bin_idx = np.array(df_x.columns.get_indexer(bin_cols))\n",
    "    nom_idx = np.array(df_x.columns.get_indexer(nom_cols))\n",
    "    int_idx = np.array(df_x.columns.get_indexer(int_cols))\n",
    "    ord_idx = np.array(df_x.columns.get_indexer(ord_cols))\n",
    "\n",
    "    print(f'Columns excluded from optimization: {list(df.columns[:2])}')\n",
    "    print()\n",
    "    if not save:\n",
    "        print('Weights are not saved in an Excel file for each λ-value!')\n",
    "\n",
    "    bnds = [(1e-14, float('inf'))] * x_d.shape[1]\n",
    "    if np.isnan(start_w):\n",
    "        start_w = [0.1] * x_d.shape[1]\n",
    "\n",
    "    # λs = [0.4, 0.38, 0.36, 0.34, 0.32, 0.3, 0.28, 0.26, 0.24, 0.22, 0.2, 0.18, 0.16, 0.14, 0.12, 0.1, 0.09, 0.08, 0.07,\n",
    "    #       0.06, 0.05, 0.03]\n",
    "    λs = [0.09]\n",
    "    w = []\n",
    "    fun = []\n",
    "\n",
    "    if len(λs) > 1:\n",
    "        save_name = 'w_' + name + '_' + str(df_copy.shape[0])\n",
    "        # Save empty dataframe to check if Excel file is closed, before optimization\n",
    "        pd.DataFrame().to_excel(f'{w_path}{save_name}.xlsx')\n",
    "    \n",
    "    t0 = time()\n",
    "    print(f'Time when starting optimizing weights: {datetime.now().strftime(\"%H:%M:%S\")}')\n",
    "\n",
    "    for idx, λ in enumerate(λs):\n",
    "        # Save empty dataframe to check if Excel file is closed, before optimization\n",
    "        save_name = 'w_' + name + '_' + str(df_copy.shape[0]) + '_' + str(λ)\n",
    "        if save:\n",
    "            pd.DataFrame().to_excel(f'{w_path}{save_name}.xlsx')\n",
    "\n",
    "        print()\n",
    "        print(f'λ = {λ}')\n",
    "        t1 = time()\n",
    "        sol = minimize(objective_weighted_podani, start_w,\n",
    "                       (x_d, x_f, y_d, y_f, bin_idx, nom_idx, int_idx, ord_idx, cols_range, λ),\n",
    "                       method='SLSQP', jac=podani_gradient, bounds=bnds)\n",
    "        w.append(sol['x'])\n",
    "        fun.append(sol['fun'])\n",
    "\n",
    "        if save:\n",
    "            pd.DataFrame(w[idx], index=df.columns[2:], columns=['w']).to_excel(\n",
    "                f'{w_path}{save_name}.xlsx')\n",
    "        time_passed = round((time() - t1) / 60, 2)\n",
    "        print(f'{time_passed}: fun = {fun[idx]}, w = {w[idx]}')\n",
    "\n",
    "    if len(λs) > 1:\n",
    "        save_name = 'w_' + name + '_' + str(df_copy.shape[0])\n",
    "        indices = list(df.columns[2:])\n",
    "        indices.insert(0, 'f_w')\n",
    "        pd.DataFrame(np.insert(np.transpose(np.array(w)), 0, fun, axis=0), index=indices, columns=λs).to_excel(\n",
    "            f'{w_path}{save_name}.xlsx')\n",
    "\n",
    "    total = (time() - t0) / 60\n",
    "    print()\n",
    "    print(f'Total runtime (in minutes): {round(total, 2)}')\n",
    "    if total > 1:\n",
    "        Beep(600, 1500)\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b6155a-d585-4013-a1a4-2de0ca43ad57",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Detect unfair instances functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ed1fc536-15ef-4048-b3fb-647940fefadf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def weighted_podani_distance(x, y, w, bin_idx, nom_idx, int_idx, ord_idx, cols_range):\n",
    "    \"\"\"\n",
    "        Calculate distance between x and y with weighted Podani distance function\n",
    "\n",
    "        :param x: x\n",
    "        :param y: y\n",
    "        :param w: array with weights\n",
    "        :param bin_idx: array with column indices of binary attributes in x & y\n",
    "        :param nom_idx: array with column indices of nominal attributes in x & y\n",
    "        :param int_idx: array with column indices of interval-scaled attributes in x & y\n",
    "        :param ord_idx: array with column indices of ordinal attributes in x & y\n",
    "        :param cols_range: array with range for each column\n",
    "        :return: distance between x and y\n",
    "        \"\"\"\n",
    "\n",
    "    wd = []\n",
    "    for col in range(0, len(x)):\n",
    "        if col in bin_idx or (col in nom_idx and x[col] == y[col]):\n",
    "            wd.append(w[col] * ((x[col] - y[col]) ** 2))\n",
    "        if col in nom_idx and x[col] != y[col]:\n",
    "            wd.append(w[col])\n",
    "        if (col in int_idx) or (col in ord_idx):\n",
    "            wd.append(w[col] * (((x[col] - y[col]) / cols_range[col]) ** 2))\n",
    "    sum_wd = sum(wd)\n",
    "    return sqrt(sum_wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "90d6edea-dce3-45b4-b9d0-29fb662e2afe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_d_matrix(df, w, bin_cols, nom_cols, int_cols, ord_cols):\n",
    "    \"\"\"\n",
    "        Compute distance matrix (excluding the sensitive attribute) for df using weighted_podani_distance\n",
    "\n",
    "        :param df: dataframe (column 0 = class_label (positive decision = 1),\n",
    "        column 1 = sensitive attribute (deprived group = 1))\n",
    "        :param w: array with weigths\n",
    "        :param bin_cols: list with column names of binary attributes in df\n",
    "        :param nom_cols: list with column names of nominal attributes in df\n",
    "        :param int_cols: list with column names of interval-scaled attributes in df\n",
    "        :param ord_cols: list with column names of ordinal attributes in df\n",
    "        :return: distance matrix\n",
    "        \"\"\"\n",
    "\n",
    "    # Exclude class label and sensitive attribute for X\n",
    "    x = df.iloc[:, 2:]\n",
    "\n",
    "    cols_range = (x.max() - x.min()).to_numpy()\n",
    "\n",
    "    bin_idx = np.array(x.columns.get_indexer(bin_cols))\n",
    "    nom_idx = np.array(x.columns.get_indexer(nom_cols))\n",
    "    int_idx = np.array(x.columns.get_indexer(int_cols))\n",
    "    ord_idx = np.array(x.columns.get_indexer(ord_cols))\n",
    "\n",
    "    x = x.to_numpy()\n",
    "\n",
    "    t_start = time()\n",
    "    print(f'Time when starting calculating d_matrix: {datetime.now().strftime(\"%H:%M:%S\")}')\n",
    "\n",
    "    d_matrix = cdist(x, x, weighted_podani_distance, w=w, bin_idx=bin_idx, nom_idx=nom_idx, int_idx=int_idx,\n",
    "                     ord_idx=ord_idx, cols_range=cols_range)\n",
    "\n",
    "    total = (time() - t_start) / 60\n",
    "    print(f'Total runtime (in minutes): {round(total, 2)}')\n",
    "    if total > 1:\n",
    "        Beep(600, 1500)\n",
    "\n",
    "    return d_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "98cb2b31-93a5-46e5-acc2-a7a679095acf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_m(data, d_matrix, name, plot=True, save=True):\n",
    "    \"\"\"\n",
    "        Get m-value for X^d and X^f for m-NN, maximum non-outlier value of distances to nearest neighbor \n",
    "        is used as m-value, but depending on the distribution of the minimum distances other values could be more fair\n",
    "\n",
    "        :param data: ndarray of dataset\n",
    "        :param d_matrix: ndarray with distance matrix\n",
    "        :param name: name of dataset\n",
    "        :param plot: whether to plot histograms of the minimum distances\n",
    "        :param save: whether to save histograms\n",
    "        :return: m for X^d and X^f\n",
    "        \"\"\"\n",
    "\n",
    "    d_0_idx = np.where((data[:, 1] == 1) & (data[:, 0] == 0))[0]\n",
    "    f_1_idx = np.where((data[:, 1] == 0) & (data[:, 0] == 1))[0]\n",
    "    d_idx = np.where(data[:, 1] == 1)[0]\n",
    "    f_idx = np.where(data[:, 1] == 0)[0]\n",
    "\n",
    "    d_rows_d_0 = d_matrix[d_0_idx, :]\n",
    "    # Distances between X^(d-) and X^f\n",
    "    d_matrix_d_0_f = d_rows_d_0[:, f_idx]\n",
    "    d_rows_f_1 = d_matrix[f_1_idx, :]\n",
    "    # Distances between X^(f+) and X^d\n",
    "    d_matrix_f_1_d = d_rows_f_1[:, d_idx]\n",
    "    minima_d_d = d_matrix_d_0_f.min(axis=1)\n",
    "    minima_d_f = d_matrix_f_1_d.min(axis=1)\n",
    "    m_d = np.quantile(minima_d_d, 0.75) + 1.5 * np.subtract(*np.percentile(minima_d_d, [75, 25]))\n",
    "    m_f = np.quantile(minima_d_f, 0.75) + 1.5 * np.subtract(*np.percentile(minima_d_f, [75, 25]))\n",
    "\n",
    "    np.fill_diagonal(d_matrix, d_matrix.max())\n",
    "    minima_d = d_matrix.min(axis=1)\n",
    "    m = np.quantile(minima_d, 0.75) + 1.5 * np.subtract(*np.percentile(minima_d, [75, 25]))\n",
    "\n",
    "    # k_d = np.count_nonzero(d_matrix_d_0_f <= m) / d_matrix_d_0_f.shape[0]\n",
    "    # k_f = np.count_nonzero(d_matrix_f_1_d <= m) / d_matrix_f_1_d.shape[0]\n",
    "    \n",
    "    plt.rcParams.update(plt.rcParamsDefault)\n",
    "    # plt.rc('font', **{'size': 13})\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12.8, 4.8))\n",
    "\n",
    "    n, bins, _ = axs[0].hist(minima_d, bins='rice')\n",
    "    axs[0].axvline(m, alpha=0.6, c='k', label=f'm≈{round(m, 3)}', linestyle='dashed')\n",
    "    axs[0].set_xlabel('Distance between x and nearest neighbor')\n",
    "    axs[0].set_ylabel('Frequence')\n",
    "    axs[0].legend()\n",
    "    freq_max = np.argmax(n)\n",
    "    center_bin = (bins[freq_max] + bins[freq_max + 1]) / 2\n",
    "    print(f'Maximum distance: {round(minima_d.max(), 2)}')\n",
    "    print(f'Center of largest bin: {round(center_bin, 2)}')\n",
    "    print()\n",
    "\n",
    "    n, bins, _ = axs[1].hist(minima_d_d, bins='rice')\n",
    "    axs[1].axvline(m, alpha=0.6, c='k', label=f'm≈{round(m, 3)}', linestyle='dashed')\n",
    "    axs[1].set_xlabel('Distance between x and nearest favored neighbor')\n",
    "    axs[1].set_ylabel('Frequence')\n",
    "    axs[1].legend()\n",
    "    freq_max = np.argmax(n)\n",
    "    center_bin = (bins[freq_max] + bins[freq_max + 1]) / 2\n",
    "    print(f'Maximum distance: {round(minima_d_d.max(), 2)}')\n",
    "    print(f'Center of largest bin: {round(center_bin, 2)}')\n",
    "    print()\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(f'{g_path}hist_minima_d_{name}_1.png', bbox_inches='tight', dpi=200, pad_inches=0.01)\n",
    "    if plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "        \n",
    "    fig, ax = plt.subplots()\n",
    "    n, bins, _ =  ax.hist(minima_d_f, bins='rice')\n",
    "    ax.axvline(m, alpha=0.6, c='k', label=f'm≈{round(m, 3)}', linestyle='dashed')\n",
    "    ax.set_xlabel('Distance between x and nearest deprived neighbor')\n",
    "    ax.set_ylabel('Frequence')\n",
    "    ax.legend()\n",
    "    freq_max = np.argsort(n)[::-1][:2]\n",
    "    # Assuming the modes are at the first/second largest bin, \n",
    "    # where the modes end up depends on the method used to calculate the optimal binwidth\n",
    "    center_bin_1 = (bins[freq_max[0]] + bins[freq_max[0] + 1]) / 2\n",
    "    center_bin_2 = (bins[freq_max[1]] + bins[freq_max[1] + 1]) / 2\n",
    "    print(f'Maximum distance: {round(minima_d_f.max(), 2)}')\n",
    "    print(f'Centers of the two \\'modes\\': {round(center_bin_1, 2)}, {round(center_bin_2, 2)}')\n",
    "    print()\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(f'{g_path}hist_minima_d_{name}_2.png', bbox_inches='tight', dpi=200, pad_inches=0.01)\n",
    "    if plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cc88010e-ba29-4005-85f4-594ec5d5993b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_unfair_instances(data, d_matrix, m, name, t=0, print_info=False, plot=False, save=False):\n",
    "    \"\"\"\n",
    "        Get indices/unfairness scores/k for unfair instances in data and U, U_n\n",
    "\n",
    "        :param data: ndarray of dataset (column 0 = class_label (positive decision = 1),\n",
    "        column 1 = sensitive attribute (deprived group = 1), column 2 = explanatory attribute)\n",
    "        :param d_matrix: ndarray with distance matrix\n",
    "        :param m: m for measuring unfairness using m-NN\n",
    "        :param name: name of dataset\n",
    "        :param t: unfairness threshold for (score > t ⇒ unfair, default=0)\n",
    "        :param print_info: whether to print information about the unfair instances\n",
    "        :param plot: whether to plot histograms of the unfairness scores\n",
    "        :param save: whether to save the histograms\n",
    "        :return: indices/unfairness scores/k of unfair instances in data, U, U_n\n",
    "        \"\"\"\n",
    "\n",
    "    d_0_idx = np.where((data[:, 1] == 1) & (data[:, 0] == 0))[0]\n",
    "    f_1_idx = np.where((data[:, 1] == 0) & (data[:, 0] == 1))[0]\n",
    "    d_idx = np.where(data[:, 1] == 1)[0]\n",
    "    f_idx = np.where(data[:, 1] == 0)[0]\n",
    "\n",
    "    disc_m_nn = []\n",
    "    favor_m_nn = []\n",
    "    disc_scores_m_nn = []\n",
    "    favor_scores_m_nn = []\n",
    "    # Averge number of neigbors used for scoring with m-NN\n",
    "    ks = []\n",
    "\n",
    "    # Find unfair deprived instances due to discrimination\n",
    "    for i in d_0_idx:\n",
    "        d = d_matrix[i, :]\n",
    "\n",
    "        # m-NN\n",
    "        m_d_nn_idx = np.where(d <= m)[0]\n",
    "        f_m_nn_idx = np.intersect1d(m_d_nn_idx, f_idx)\n",
    "\n",
    "        # There's no evidence for discrimination for deprived instance i \n",
    "        # if no favored instance is found within a distance m (len(f_m_nn_idx) = 0), \n",
    "        # therefore the index i should not be added to disc_idx_m_nn\n",
    "        if len(f_m_nn_idx) > t:\n",
    "            disc_score_m_nn = np.mean(data[f_m_nn_idx, 0])\n",
    "            disc_scores_m_nn.append(disc_score_m_nn)\n",
    "            ks.append(len(f_m_nn_idx))\n",
    "            if disc_score_m_nn > t:\n",
    "                disc_m_nn.append([i, disc_score_m_nn, len(f_m_nn_idx)])\n",
    "\n",
    "    # Find unfair favored instances due to favoritism\n",
    "    for j in f_1_idx:\n",
    "        d = d_matrix[j, :]\n",
    "\n",
    "        # m-NN\n",
    "        m_f_nn_idx = np.where(d <= m)[0]\n",
    "        d_m_nn_idx = np.intersect1d(m_f_nn_idx, d_idx)\n",
    "\n",
    "        # There's no evidence for favoritism for favored instance j\n",
    "        # if no deprived instance is found within a distance m (len(d_m_nn_idx) = 0), \n",
    "        # therefore the index j should not be added to favor_idx_m_nn\n",
    "        if len(d_m_nn_idx) > t:\n",
    "            # F_m = #instances with a negative class label = 1 - #instances with a positive class label\n",
    "            favor_score_m_nn = 1 - np.mean(data[d_m_nn_idx, 0])\n",
    "            favor_scores_m_nn.append(favor_score_m_nn)\n",
    "            ks.append(len(d_m_nn_idx))\n",
    "            if favor_score_m_nn > t:                \n",
    "                favor_m_nn.append([j, favor_score_m_nn, len(d_m_nn_idx)])\n",
    "\n",
    "    # Average unfairness score\n",
    "    if len(disc_scores_m_nn) > 0 or len(favor_scores_m_nn) > 0:\n",
    "        u = (sum(disc_scores_m_nn) + sum(favor_scores_m_nn)) / (len(disc_scores_m_nn) + len(favor_scores_m_nn))\n",
    "    else:\n",
    "        u = 0\n",
    "\n",
    "    # Percentage of instances with an unfairness score\n",
    "    u_n = (len(disc_scores_m_nn) + len(favor_scores_m_nn)) / data.shape[0]\n",
    "    if len(ks) > 0:\n",
    "        mean_ks = sum(ks) / len(ks)\n",
    "    else:\n",
    "        mean_ks = np.nan\n",
    "\n",
    "    if print_info:\n",
    "        print(f'Dataset: {name}')\n",
    "        print(f'Number of unfair deprived instances: {len(disc_m_nn)} (FRL)')\n",
    "        print(f'Number of unfair favored instances: {len(favor_m_nn)} (FRL)')\n",
    "        print(f'Mean number of neighbors within {round(m, 2)} distance: {round(mean_ks, 2)}')\n",
    "\n",
    "    # s_factor = 4.21 / 1.25\n",
    "    plt.rcParams.update(plt.rcParamsDefault)\n",
    "    # plt.rc('font', **{'size': 13 / s_factor})\n",
    "    # plt.rcParams['figure.figsize'] = (6.4 / s_factor, 4.8 / s_factor)\n",
    "    # plt.rcParams['axes.linewidth'] = 1 / s_factor\n",
    "    # plt.rcParams[\"xtick.major.size\"] = 3.5 / s_factor\n",
    "    # plt.rcParams[\"ytick.major.size\"] = 3.5 / s_factor\n",
    "    # plt.rcParams[\"patch.linewidth\"] = 1 / s_factor\n",
    "    plt.hist(disc_scores_m_nn, range=(0, 1), alpha=0.7, label=r'$D_m$-score', bins='rice')\n",
    "    plt.hist(favor_scores_m_nn, range=(0, 1), alpha=0.7, label=r'$F_m$-score', bins='rice')\n",
    "    plt.axvline(x=u, alpha=0.4, color='k', label=fr'$U$≈{round(u, 2)} ($U_n$≈{round(u_n, 2)})', linestyle='dashed')\n",
    "    plt.xlabel(f'Unfairness score (m≈{round(m, 3)})')\n",
    "    plt.ylabel('Frequence')\n",
    "    plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{g_path}hist_u_scores_{name}.png', bbox_inches='tight', dpi=300, pad_inches=0.01)\n",
    "    if plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "\n",
    "    disc_m_nn_np = np.array(disc_m_nn)\n",
    "    favor_m_nn_np = np.array(favor_m_nn)\n",
    "    if len(disc_m_nn_np) > 0:\n",
    "        disc_m_nn_np = disc_m_nn_np[np.argsort(-disc_m_nn_np[:, 1])]\n",
    "    if len(favor_m_nn_np) > 0:\n",
    "        favor_m_nn_np = favor_m_nn_np[np.argsort(-favor_m_nn_np[:, 1])]\n",
    "\n",
    "    return disc_m_nn_np, favor_m_nn_np, u, u_n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ad8318-a471-4081-b1dd-4a1c96aa4b63",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Get weights, d_matrix, m for all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e2acc56a-4eca-426e-a472-ddfa93e670ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_matrix_adult = np.empty(0)\n",
    "m_adult = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ddd47bca-b2f3-41be-b6e3-c6253873519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df_adult = df_adult_original.sample(frac=0.15, random_state=state).reset_index(drop=True)\n",
    "# # w_adult = get_w(df_adult, bin_cols_adult, nom_cols_adult, int_cols_adult, ord_cols_adult, 'adult', save=0)\n",
    "\n",
    "# df_adult = df_adult_original.sample(frac=0.5, random_state=state).reset_index(drop=True)\n",
    "# w_adult = pd.read_excel(f'{w_path}w_adult_9044_0.09.xlsx', usecols=['w']).to_numpy()\n",
    "# # df_adult = df_adult_original.sample(frac=0.025, random_state=state).reset_index(drop=True)\n",
    "# d_matrix_adult = get_d_matrix(df_adult, w_adult[0], bin_cols_adult, nom_cols_adult, int_cols_adult, ord_cols_adult)\n",
    "# # m_adult = get_m(df_adult.to_numpy(), d_matrix_adult, 'adult')\n",
    "# # _, _, _, _ = get_unfair_instances(df_adult.to_numpy(), d_matrix_adult, m_adult, 'adult', plot=1, save=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "391c316e-8736-4ed5-b57d-a3a99a26b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_matrix_compas = np.empty(0)\n",
    "m_compas = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6dac7004-09e8-4a1e-ac90-40d461bc6af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # w_compas = get_w(df_compas, bin_cols_compas, nom_cols_compas, int_cols_compas, ord_cols_compas, 'compas', save=1)\n",
    "# w_compas = pd.read_excel(f'{w_path}w_compas_8946_0.09.xlsx', usecols=['w']).to_numpy()\n",
    "# # df_compas = df_compas_original.sample(frac=0.1, random_state=state).reset_index(drop=True)\n",
    "# d_matrix_compas = get_d_matrix(df_compas, w_compas[0], bin_cols_compas, nom_cols_compas, int_cols_compas, ord_cols_compas)\n",
    "# # m_compas = get_m(df_compas.to_numpy(), d_matrix_compas, 'compas')\n",
    "# # _, _, _, _ = get_unfair_instances(df_compas.to_numpy(), d_matrix_compas, m_compas, 'compas', plot=1, save=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "da070d56-44d8-422c-a9c7-8cb6b30bbc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_matrix_ar = np.empty(0)\n",
    "m_ar = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "32775bd6-154a-443f-8b0b-b3d1b4dde048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # w_ar = get_w(df_ar, bin_cols_ar, nom_cols_ar, int_cols_ar, ord_cols_ar, 'ar', save=1)\n",
    "# w_ar = pd.read_excel(f'{w_path}w_ar_2887_0.09.xlsx', usecols=['w']).to_numpy()\n",
    "# # df_ar = df_ar_original.sample(frac=0.4, random_state=state).reset_index(drop=True)\n",
    "# d_matrix_ar = get_d_matrix(df_ar, w_ar[0], bin_cols_ar, nom_cols_ar, int_cols_ar, ord_cols_ar)\n",
    "# m_ar = get_m(df_ar.to_numpy(), d_matrix_ar, 'ar')\n",
    "# _, _, _, _ = get_unfair_instances(df_ar.to_numpy(), d_matrix_ar, m_ar, 'ar', plot=1, save=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d194f1-eb4f-4978-96d0-6dd266826a41",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a46ed050-fd6e-40a0-82ae-e9c3f5796508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [pr_nbs_adult_nan, pr_1nn_adult_nan, pr_3nn_adult_nan, pr_7nn_adult_nan, pr_dt_adult_nan,\n",
    "#  pr_logit_adult_nan] = load_metrics(\n",
    "#     ['pr_nbs_adult', 'pr_1nn_adult', 'pr_3nn_adult', 'pr_7nn_adult', 'pr_dt_adult', 'pr_logit_adult'],\n",
    "#     'Code outputs/Metrics/Adult without U/')\n",
    "# [pr_nbs_adult_u, pr_1nn_adult_u, pr_3nn_adult_u, pr_7nn_adult_u, pr_dt_adult_u, pr_logit_adult_u] = load_metrics(\n",
    "#     ['pr_nbs_adult', 'pr_1nn_adult', 'pr_3nn_adult', 'pr_7nn_adult', 'pr_dt_adult', 'pr_logit_adult'],\n",
    "#     'Code outputs/Metrics/Adult with U/')\n",
    "\n",
    "# [frw_nbs_adult_nan, frw_dt_adult_nan, frw_logit_adult_nan] = load_metrics(\n",
    "#     ['frw_nbs_adult', 'frw_dt_adult', 'frw_logit_adult'], 'Code outputs/Metrics/Adult without U/')\n",
    "# [frw_nbs_adult_u, frw_dt_adult_u, frw_logit_adult_u] = load_metrics(\n",
    "#     ['frw_nbs_adult', 'frw_dt_adult', 'frw_logit_adult'], 'Code outputs/Metrics/Adult with U/')\n",
    "\n",
    "# [fps_nbs_adult_nan, fps_1nn_adult_nan, fps_3nn_adult_nan, fps_7nn_adult_nan, fps_dt_adult_nan,\n",
    "#  fps_logit_adult_nan] = load_metrics(\n",
    "#     ['fps_nbs_adult', 'fps_1nn_adult', 'fps_3nn_adult', 'fps_7nn_adult', 'fps_dt_adult', 'fps_logit_adult'],\n",
    "#     'Code outputs/Metrics/Adult without U/')\n",
    "# [fps_nbs_adult_u, fps_1nn_adult_u, fps_3nn_adult_u, fps_7nn_adult_u, fps_dt_adult_u, fps_logit_adult_u] = load_metrics(\n",
    "#     ['fps_nbs_adult', 'fps_1nn_adult', 'fps_3nn_adult', 'fps_7nn_adult', 'fps_dt_adult', 'fps_logit_adult'],\n",
    "#     'Code outputs/Metrics/Adult with U/')\n",
    "\n",
    "# [frl_nbs_adult, frl_1nn_adult, frl_3nn_adult, frl_7nn_adult, frl_dt_adult, frl_logit_adult] = load_metrics(\n",
    "#     ['frl_nbs_adult', 'frl_1nn_adult', 'frl_3nn_adult', 'frl_7nn_adult', 'frl_dt_adult', 'frl_logit_adult'],\n",
    "#     'Code outputs/Metrics/Adult with U/')\n",
    "\n",
    "# [pr_nbs_compas, pr_1nn_compas, pr_3nn_compas, pr_7nn_compas, pr_dt_compas, pr_logit_compas, pr_nbs_ar, pr_1nn_ar,\n",
    "#  pr_3nn_ar, pr_7nn_ar, pr_dt_ar, pr_logit_ar] = load_metrics(\n",
    "#     ['pr_nbs_compas_te', 'pr_1nn_compas_te', 'pr_3nn_compas_te', 'pr_7nn_compas_te', 'pr_dt_compas_te',\n",
    "#      'pr_logit_compas_te', 'pr_nbs_ar', 'pr_1nn_ar', 'pr_3nn_ar', 'pr_7nn_ar', 'pr_dt_ar', 'pr_logit_ar'], m_path)\n",
    "\n",
    "# [frw_nbs_compas, frw_dt_compas, frw_logit_compas, frw_nbs_ar, frw_dt_ar, frw_logit_ar] = load_metrics(\n",
    "#     ['frw_nbs_compas_te', 'frw_dt_compas_te', 'frw_logit_compas_te', 'frw_nbs_ar', 'frw_dt_ar', 'frw_logit_ar'], m_path)\n",
    "\n",
    "# [fps_nbs_compas, fps_1nn_compas, fps_3nn_compas, fps_7nn_compas, fps_dt_compas, fps_logit_compas, fps_nbs_ar,\n",
    "#  fps_1nn_ar, fps_3nn_ar, fps_7nn_ar, fps_dt_ar, fps_logit_ar] = load_metrics(\n",
    "#     ['fps_nbs_compas_te', 'fps_1nn_compas_te', 'fps_3nn_compas_te', 'fps_7nn_compas_te', 'fps_dt_compas_te',\n",
    "#      'fps_logit_compas_te', 'fps_nbs_ar', 'fps_1nn_ar', 'fps_3nn_ar', 'fps_7nn_ar', 'fps_dt_ar', 'fps_logit_ar'],\n",
    "#     m_path)\n",
    "\n",
    "# [frl_nbs_compas, frl_1nn_compas, frl_3nn_compas, frl_7nn_compas, frl_dt_compas, frl_logit_compas, frl_nbs_ar,\n",
    "#  frl_1nn_ar, frl_3nn_ar, frl_7nn_ar, frl_dt_ar, frl_logit_ar] = load_metrics(\n",
    "#     ['frl_nbs_compas_te', 'frl_1nn_compas_te', 'frl_3nn_compas_te', 'frl_7nn_compas_te', 'frl_dt_compas_te',\n",
    "#      'frl_logit_compas_te', 'frl_nbs_ar', 'frl_1nn_ar', 'frl_3nn_ar', 'frl_7nn_ar', 'frl_dt_ar', 'frl_logit_ar'],\n",
    "#     m_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8b8dce77-c640-407c-bbf3-79e42841acda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = get_rl_metrics(\n",
    "#     [frl_nbs_adult, frl_nbs_compas, frl_nbs_ar, frl_7nn_adult, frl_7nn_compas, frl_7nn_ar, frl_dt_adult, frl_dt_compas,\n",
    "#      frl_dt_ar, frl_logit_adult, frl_logit_compas, frl_logit_ar],\n",
    "#     ['NBS - Adult', 'NBS - COMPAS', 'NBS - AdviceRobo', '7-NN - Adult', '7-NN - COMPAS', '7-NN - AdviceRobo',\n",
    "#      'DT - Adult', 'DT - COMPAS', 'DT - AdviceRobo', 'Logit - Adult', 'Logit - COMPAS', 'Logit - AdviceRobo'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3ff34b80-19ad-4ff4-8fe4-02697d9a911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, _ = create_metrics_table([[[[pr_nbs_adult_nan, pr_nbs_adult_u], 'baseline', 'baseline'],\n",
    "#                               [[pr_nbs_adult_nan, pr_nbs_adult_u], 0.975, 0.975],\n",
    "#                               [[frw_nbs_adult_nan, frw_nbs_adult_u], 7.6, 5.2],\n",
    "#                               [[fps_nbs_adult_nan, fps_nbs_adult_u], 5.9375, 4.0625], [frl_nbs_adult, 'rl', 'rl'],\n",
    "#                               [frl_nbs_adult, 1, 0.4], [pr_nbs_compas, 'baseline', 'baseline'],\n",
    "#                               [pr_nbs_compas, 0.9, 0.975], [frw_nbs_compas, 4.6875, 3.4375], [fps_nbs_compas, 3.25, 3],\n",
    "#                               [frl_nbs_compas, 'rl', 'rl'], [frl_nbs_compas, 0.85, 1],\n",
    "#                               [pr_nbs_ar, 'baseline', 'baseline'], [pr_nbs_ar, 0.575, 0.975], [frw_nbs_ar, 2.4, 5.2],\n",
    "#                               [fps_nbs_ar, 1.875, 4.6875], [frl_nbs_ar, 'rl', 'rl'], [frl_nbs_ar, 0.45, 0.8]],\n",
    "#                              [[[pr_7nn_adult_nan, pr_7nn_adult_u], 'baseline', 'baseline'],\n",
    "#                               [[pr_7nn_adult_nan, pr_7nn_adult_u], 0.7, 0.725], [pd.DataFrame(), np.nan, np.nan],\n",
    "#                               [[fps_7nn_adult_nan, fps_7nn_adult_u], 5.625, 0.3125], [frl_7nn_adult, 'rl', 'rl'],\n",
    "#                               [frl_7nn_adult, 1, 0.3], [pr_7nn_compas, 'baseline', 'baseline'],\n",
    "#                               [pr_7nn_compas, 0.575, 0.725], [pd.DataFrame(), np.nan, np.nan], [fps_7nn_compas, 1, 1.6],\n",
    "#                               [frl_7nn_compas, 'rl', 'rl'], [frl_7nn_compas, 0.45, 0.5],\n",
    "#                               [pr_7nn_ar, 'baseline', 'baseline'], [pr_7nn_ar, 0.55, 0.725],\n",
    "#                               [pd.DataFrame(), np.nan, np.nan], [fps_7nn_ar, 0.56, 0.96], [frl_7nn_ar, 'rl', 'rl'],\n",
    "#                               [frl_7nn_ar, 0.25, 0.55]],\n",
    "#                              [[[pr_dt_adult_nan, pr_dt_adult_u], 'baseline', 'baseline'],\n",
    "#                               [[pr_dt_adult_nan, pr_dt_adult_u], 0.7, 0.725],\n",
    "#                               [[frw_dt_adult_nan, frw_dt_adult_u], 4.5, 0.25],\n",
    "#                               [[fps_dt_adult_nan, fps_dt_adult_u], 1.8, 0.8], [frl_dt_adult, 'rl', 'rl'],\n",
    "#                               [frl_dt_adult, 0.75, 0], [pr_dt_compas, 'baseline', 'baseline'],\n",
    "#                               [pr_dt_compas, 0.6, 0.775], [frw_dt_compas, 2.25, 2.5], [fps_dt_compas, 1, 2],\n",
    "#                               [frl_dt_compas, 'rl', 'rl'], [frl_dt_compas, 0.35, 0.6],\n",
    "#                               [pr_dt_ar, 'baseline', 'baseline'], [pr_dt_ar, 0.675, 0.775], [frw_dt_ar, 2, 7.5],\n",
    "#                               [fps_dt_ar, 1, 10], [frl_dt_ar, 'rl', 'rl'], [frl_dt_ar, 0.6, 0.5]],\n",
    "#                              [[[pr_logit_adult_nan, pr_logit_adult_u], 'baseline', 'baseline'],\n",
    "#                               [[pr_logit_adult_nan, pr_logit_adult_u], 0.7, 0.775],\n",
    "#                               [[frw_logit_adult_nan, frw_logit_adult_u], 5.9375, 2.5],\n",
    "#                               [[fps_logit_adult_nan, fps_logit_adult_u], 3.8, 1.8], [frl_logit_adult, 'rl', 'rl'],\n",
    "#                               [frl_logit_adult, 1, 0.85], [pr_logit_compas, 'baseline', 'baseline'],\n",
    "#                               [pr_logit_compas, 0.625, 0.85], [frw_logit_compas, 1.5, 2], [fps_logit_compas, 0.64, 0.8],\n",
    "#                               [frl_logit_compas, 'rl', 'rl'], [frl_logit_compas, 0.25, 0.4],\n",
    "#                               [pr_logit_ar, 'baseline', 'baseline'], [pr_logit_ar, 0.65, 0.775],\n",
    "#                               [frw_logit_ar, 3.5, 10], [fps_logit_ar, 2, 8], [frl_logit_ar, 'rl', 'rl'],\n",
    "#                               [frl_logit_ar, 0.6, 0.5]]],\n",
    "#                             ['Adult - baseline', 'Adult - PR', 'Adult - FRW', 'Adult - FPS', 'Adult - RL',\n",
    "#                              'Adult - FRL', 'COMPAS - baseline', 'COMPAS - PR', 'COMPAS - FRW', 'COMPAS - FPS',\n",
    "#                              'COMPAS - RL', 'COMPAS - FRL', 'AdviceRobo - baseline', 'AdviceRobo - PR',\n",
    "#                              'AdviceRobo - FRW', 'AdviceRobo - FPS', 'AdviceRobo - RL', 'AdviceRobo - FRL'],\n",
    "#                             ['NBS', '7-NN', 'DT', 'Logit'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e19abdde-d473-4b83-98cb-269571ec8e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frl_logit_compas.style.background_gradient(cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9ae3fb-1f76-4f18-b5c5-907557924cf7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Probabilistic Rejection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a89dbd9a-6fcf-4715-8bad-c270daa610a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def post_proces(clf, clf_name, df, df_name, cat_cols, nom_cols, thetas=None, test=True, d_matrix=np.empty(0), m=np.nan,\n",
    "                n_bins=[10], drop_s=False, print_metrics=True, export=True, no_print=False):\n",
    "    \"\"\"\n",
    "        Applies PR on validation/test predictions\n",
    "\n",
    "        :param clf: instance of classifier (use clf=None for NBS)\n",
    "        :param clf_name: name of classifier\n",
    "        :param df: dataframe (column 0 = class_label (positive decision = 1),\n",
    "        column 1 = sensitive attribute (deprived group = 1), column 2 = explanatory attribute)\n",
    "        :param df_name: name of dataset\n",
    "        :param cat_cols: list with column names of categorical attributes in df (needed for NBS)\n",
    "        :param nom_cols: list with column names of nominal attributes in df (needed for one-hot-encoding)\n",
    "        :param thetas: list with theta parameters to tune accuracy-fairness (default=None)\n",
    "        :param test: whether to make predictions for the test or validation set (default=False)\n",
    "        :param d_matrix: ndarray with distance matrix for measuring individual unfairness U (default=np.empty(0))\n",
    "        :param m: m for measuring individual unfairness U using m-NN (default=np.nan)\n",
    "        :param n_bins: number of bins used to discretize the explanatory attribute\n",
    "        :param drop_s: whether to drop the sensitive attribute for training/prediction or not (default=False)\n",
    "        :param print_metrics: print dataframe with metrics (default=True)\n",
    "        :param export: whether to export the metrics (default=True)\n",
    "        :param no_print: whether to not print anything or print everything (default=False,\n",
    "        =True when tuning hyperparameters for DT)\n",
    "        :return: dataframe with metrics\n",
    "    \"\"\"\n",
    "\n",
    "    if clf_name == 'knn':\n",
    "        save_name = str(clf.get_params()['n_neighbors']) + clf_name[1:] + '_' + df_name\n",
    "    else:\n",
    "        save_name = clf_name + '_' + df_name\n",
    "    if not no_print:\n",
    "        print(' ' * 50 + clf_name + ' - ' + df_name)\n",
    "    if export:\n",
    "        if not test:\n",
    "            pd.DataFrame().to_excel(f'{m_path}pr_{save_name}_val.xlsx')\n",
    "        else:\n",
    "            pd.DataFrame().to_excel(f'{m_path}pr_{save_name}_te.xlsx')\n",
    "\n",
    "    y_pr_val, y_pr_te = train(clf, clf_name, df, cat_cols, nom_cols, test=test, drop_s=drop_s, no_print=no_print)\n",
    "\n",
    "    if not test:\n",
    "        y_pr = y_pr_val\n",
    "    else:\n",
    "        y_pr = y_pr_te\n",
    "    y_pr['1_min_p'] = 1 - y_pr['y_prob']\n",
    "    y_pr['max'] = y_pr[['y_prob', '1_min_p']].max(axis=1)\n",
    "    y_pr['baseline'] = y_pr['y_prob']\n",
    "    for theta in thetas:\n",
    "        # Rounding down\n",
    "        y_pr[theta] = (y_pr['y_prob'] > 0.5).astype(int)\n",
    "        y_pr.loc[(y_pr['max'] <= theta) & (y_pr[theta] == 1) & (y_pr['s'] == 0), theta] = 0\n",
    "        y_pr.loc[(y_pr['max'] <= theta) & (y_pr[theta] == 0) & (y_pr['s'] == 1), theta] = 1\n",
    "    metrics_df = get_metrics(y_pr.drop(['y_prob', '1_min_p', 'max'], axis=1), df, d_matrix, m, df_name,\n",
    "                             cat_cols, n_bins=n_bins)\n",
    "\n",
    "    if export:\n",
    "        if not test:\n",
    "            metrics_df.to_excel(f'{m_path}pr_{save_name}_val.xlsx')\n",
    "        else:\n",
    "            metrics_df.to_excel(f'{m_path}pr_{save_name}_te.xlsx')\n",
    "    if print_metrics:\n",
    "        print(metrics_df)\n",
    "    if not no_print:\n",
    "        print('-' * 100)\n",
    "\n",
    "    return metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4b14b830-bdf3-48b2-a785-412f3137af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This DT classifier is used for all datasets/techniques\n",
    "# df_adult with instances 48842 instances\n",
    "dt_clf = DecisionTreeClassifier(random_state=state, min_samples_leaf=0.02)\n",
    "# df_adult with 1131 instances\n",
    "# dt_clf = DecisionTreeClassifier(random_state=state, min_samples_split=0.26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bb32b900-dc2a-4c3e-860b-c8925256685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_thetas = np.round(np.arange(0.525, 1, 0.025), 4).tolist()\n",
    "\n",
    "# pr_nbs_adult = post_proces(None, 'nbs', df_adult, 'adult', cat_cols_adult, nom_cols_adult, pr_thetas)\n",
    "# pr_1nn_adult = post_proces(KNeighborsClassifier(n_neighbors=1), 'knn', df_adult, 'adult', cat_cols_adult,\n",
    "#                            nom_cols_adult, pr_thetas)\n",
    "# pr_3nn_adult = post_proces(KNeighborsClassifier(n_neighbors=3), 'knn', df_adult, 'adult', cat_cols_adult,\n",
    "#                            nom_cols_adult, pr_thetas)\n",
    "# pr_7nn_adult = post_proces(KNeighborsClassifier(n_neighbors=7), 'knn', df_adult, 'adult', cat_cols_adult,\n",
    "#                            nom_cols_adult, pr_thetas)\n",
    "# pr_dt_adult = post_proces(dt_clf, 'dt', df_adult, 'adult', cat_cols_adult, nom_cols_adult, pr_thetas)\n",
    "# pr_logit_adult = post_proces(LogisticRegression(random_state=state, max_iter=3000), 'logit', df_adult, 'adult',\n",
    "#                              cat_cols_adult, nom_cols_adult, pr_thetas)\n",
    "\n",
    "# pr_nbs_compas = post_proces(None, 'nbs', df_compas, 'compas', cat_cols_compas, nom_cols_compas, pr_thetas, n_bins=[6])\n",
    "# pr_1nn_compas = post_proces(KNeighborsClassifier(n_neighbors=1), 'knn', df_compas, 'compas', cat_cols_compas,\n",
    "#                             nom_cols_compas, pr_thetas, n_bins=[6])\n",
    "# pr_3nn_compas = post_proces(KNeighborsClassifier(n_neighbors=3), 'knn', df_compas, 'compas', cat_cols_compas,\n",
    "#                             nom_cols_compas, pr_thetas, n_bins=[6])\n",
    "# pr_7nn_compas = post_proces(KNeighborsClassifier(n_neighbors=7), 'knn', df_compas, 'compas', cat_cols_compas,\n",
    "#                             nom_cols_compas, pr_thetas, n_bins=[6])\n",
    "# pr_dt_compas = post_proces(dt_clf, 'dt', df_compas, 'compas', cat_cols_compas, nom_cols_compas, pr_thetas, n_bins=[6])\n",
    "# pr_logit_compas = post_proces(LogisticRegression(random_state=state, max_iter=1000), 'logit', df_compas, 'compas',\n",
    "#                               cat_cols_compas, nom_cols_compas, pr_thetas, n_bins=[6])\n",
    "\n",
    "# pr_nbs_ar = post_proces(None, 'nbs', df_ar, 'ar', cat_cols_ar, nom_cols_ar, pr_thetas)\n",
    "# # Hard to remove D_u for all k-NN clfs for AR dataset, since there's not much D_u left in their predictions\n",
    "# pr_1nn_ar = post_proces(KNeighborsClassifier(n_neighbors=1), 'knn', df_ar, 'ar', cat_cols_ar, nom_cols_ar, pr_thetas)\n",
    "# pr_3nn_ar = post_proces(KNeighborsClassifier(n_neighbors=3), 'knn', df_ar, 'ar', cat_cols_ar, nom_cols_ar, pr_thetas)\n",
    "# pr_7nn_ar = post_proces(KNeighborsClassifier(n_neighbors=7), 'knn', df_ar, 'ar', cat_cols_ar, nom_cols_ar, pr_thetas)\n",
    "# pr_dt_ar = post_proces(dt_clf, 'dt', df_ar, 'ar', cat_cols_ar, nom_cols_ar, pr_thetas)\n",
    "# pr_logit_ar = post_proces(LogisticRegression(random_state=state, max_iter=1000), 'logit', df_ar, 'ar', cat_cols_ar,\n",
    "#                           nom_cols_ar, pr_thetas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c160df2-292c-4fcb-af99-4a6c199ab71b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fair Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3654def3-296b-4888-ab7c-d47b7d0be668",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reweight(clf, clf_name, df, df_name, cat_cols, nom_cols, gammas=None, test=True, d_matrix=np.empty(0), m=np.nan,\n",
    "             n_bins=[10], drop_s=False, print_weights=False, print_metrics=True, export=True, no_print=False):\n",
    "    \"\"\"\n",
    "        Applies FRW on training set\n",
    "\n",
    "        :param clf: instance of classifier (use clf=None for NBS)\n",
    "        :param clf_name: name of classifier\n",
    "        :param df: dataframe (column 0 = class_label (positive decision = 1),\n",
    "        column 1 = sensitive attribute (deprived group = 1), column 2 = explanatory attribute)\n",
    "        :param df_name: name of dataset\n",
    "        :param cat_cols: list with column names of categorical attributes in df (needed for NBS)\n",
    "        :param nom_cols: list with column names of nominal attributes in df (needed for one-hot-encoding)\n",
    "        :param gammas: list with gamma parameters to tune accuracy-fairness (default=None)\n",
    "        :param test: whether to make predictions for the test or validation set (default=False)\n",
    "        :param d_matrix: ndarray with distance matrix for measuring individual unfairness U (default=np.empty(0))\n",
    "        :param m: m for measuring individual unfairness U using m-NN (default=np.nan)\n",
    "        :param n_bins: number of bins used to discretize the explanatory attribute (default=10)\n",
    "        :param drop_s: whether to drop the sensitive attribute for training/prediction or not (default=False)\n",
    "        :param print_weights: print percentage of weigthed instances and weigths (default=False)\n",
    "        :param print_metrics: print dataframe with metrics (default=True)\n",
    "        :param export: whether to export the metrics (default=True)\n",
    "        :param no_print: whether to not print anything or print everything (default=False,\n",
    "        =True when tuning hyperparameters for DT)\n",
    "        :return: dataframe with metrics\n",
    "    \"\"\"\n",
    "\n",
    "    save_name = clf_name + '_' + df_name\n",
    "    if not no_print:\n",
    "        print(' ' * 50 + clf_name + ' - ' + df_name)\n",
    "    if export:\n",
    "        if not test:\n",
    "            pd.DataFrame().to_excel(f'{m_path}frw_{save_name}_val.xlsx')\n",
    "        else:\n",
    "            pd.DataFrame().to_excel(f'{m_path}frw_{save_name}_te.xlsx')\n",
    "\n",
    "    y_pr_val_0, y_pr_te_0 = train(clf, clf_name, df, cat_cols, nom_cols, test=test, drop_s=drop_s, no_print=no_print)\n",
    "    if not test:\n",
    "        fnr_d, fpr_d, fnr_f, fpr_f, d_ix, f_ix = get_misclassification_metrics(y_pr_val_0)\n",
    "    else:\n",
    "        fnr_d, fpr_d, fnr_f, fpr_f, d_ix, f_ix = get_misclassification_metrics(y_pr_te_0)\n",
    "\n",
    "    if print_weights:\n",
    "        d_fn_percentage = (d_ix.shape[0] / df.shape[0]) * 100\n",
    "        f_fp_percentage = (f_ix.shape[0] / df.shape[0]) * 100\n",
    "        print(f'Weighted X^d: {round(d_fn_percentage, 2)}%')\n",
    "        print(f'Weighted X^f: {round(f_fp_percentage, 2)}%')\n",
    "        print(f'Weights (γ=1) for X^d: {round(fnr_d / fnr_f, 2)}')\n",
    "        print(f'Weights (γ=1) for X^f: {round(fpr_d / fpr_f, 2)}')\n",
    "        print()\n",
    "\n",
    "    gammas.insert(0, 'baseline')\n",
    "    sample_weights = [gammas, np.ones(df.shape[0])]\n",
    "    for gamma in gammas[1:]:\n",
    "        w_d = gamma * fnr_d / fnr_f\n",
    "        w_f = gamma * fpr_d / fpr_f\n",
    "\n",
    "        sample_weight = np.ones(df.shape[0])\n",
    "        sample_weight[d_ix] = w_d\n",
    "        sample_weight[f_ix] = w_f\n",
    "\n",
    "        sample_weights.append(sample_weight)\n",
    "\n",
    "    y_pr_val_1, y_pr_te_1 = train(clf, clf_name, df, cat_cols, nom_cols, 'frw', sample_weights, test, drop_s, no_print)\n",
    "\n",
    "    if not test:\n",
    "        metrics_df = get_metrics(y_pr_val_1, df, d_matrix, m, df_name, cat_cols, n_bins=n_bins)\n",
    "    else:\n",
    "        metrics_df = get_metrics(y_pr_te_1, df, d_matrix, m, df_name, cat_cols, n_bins=n_bins)\n",
    "\n",
    "    if export:\n",
    "        if not test:\n",
    "            metrics_df.to_excel(f'{m_path}frw_{save_name}_val.xlsx')\n",
    "        else:\n",
    "            metrics_df.to_excel(f'{m_path}frw_{save_name}_te.xlsx')\n",
    "    if print_metrics:\n",
    "        print(metrics_df)\n",
    "    if not no_print:\n",
    "        print('-' * 100)\n",
    "\n",
    "    return metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f6dbd3cd-1b4c-4b88-af64-a0f31988e8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = 0\n",
    "# stop = 0.1\n",
    "# step = (stop - start) / 20\n",
    "\n",
    "# param_values = np.round(np.arange(start+step, stop+step, step), 10).tolist()\n",
    "# param_values = [0.02]\n",
    "# # param_values = [int(x) for x in (np.arange(start+step, stop+step, step)).tolist()]\n",
    "# # param_values = [46]\n",
    "# # print(len(param_values))\n",
    "# print(param_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fafd9ed7-16a5-407f-9b8b-dfab242c916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in param_values:\n",
    "#     model = DecisionTreeClassifier(random_state=state, min_samples_leaf=p)\n",
    "#     pr_dt_ar = post_proces(model, 'dt', df_ar, 'ar', cat_cols_ar, nom_cols_ar, pr_thetas, test=0, print_metrics=0,\n",
    "#                            export=0, no_print=1)\n",
    "#     pr_dt_adult = post_proces(dt_clf, 'dt', df_adult, 'adult', cat_cols_adult, nom_cols_adult, pr_thetas, test=0,\n",
    "#                               print_metrics=0, export=0, no_print=1)\n",
    "#     frw_dt_ar = reweight(model, 'dt', df_ar, 'ar', cat_cols_ar, nom_cols_ar, [g / 1.6 for g in [*range(1, 21, 1)]],\n",
    "#                          test=0, print_metrics=0, export=0, no_print=1)\n",
    "#     frw_dt_adult = reweight(model, 'dt', df_adult, 'adult', cat_cols_adult, nom_cols_adult,\n",
    "#                             [g / 3.2 for g in [*range(1, 21, 1)]], test=0, print_metrics=0, export=0, no_print=1)\n",
    "#     print(f'param_value={p}')\n",
    "#     plot_metrics([[[pr_dt_ar, pr_dt_adult, frw_dt_ar, frw_dt_adult], ['PR_ar', 'PR_adult', 'FRW_ar', 'FRW_adult'], 4]],\n",
    "#                  'test', 1, save=0,\n",
    "#                  no_print=1)\n",
    "# Beep(600, 1500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c6d723e5-af82-441f-9f88-3ab9fe1bbc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frw_nbs_adult = reweight(None, 'nbs', df_adult, 'adult', cat_cols_adult, nom_cols_adult,\n",
    "#                          [g / 2.5 for g in [*range(1, 21, 1)]])\n",
    "# frw_dt_adult = reweight(dt_clf, 'dt', df_adult, 'adult', cat_cols_adult, nom_cols_adult,\n",
    "#                         [g / 3.2 for g in [*range(1, 21, 1)]])\n",
    "# frw_logit_adult = reweight(LogisticRegression(random_state=state, max_iter=5000), 'logit', df_adult, 'adult',\n",
    "#                            cat_cols_adult, nom_cols_adult, [g / 3.2 for g in [*range(1, 21, 1)]])\n",
    "\n",
    "# frw_nbs_compas = reweight(None, 'nbs', df_compas, 'compas', cat_cols_compas, nom_cols_compas,\n",
    "#                           [g / 3.2 for g in [*range(1, 21, 1)]], n_bins=[6])\n",
    "# frw_dt_compas = reweight(dt_clf, 'dt', df_compas, 'compas', cat_cols_compas, nom_cols_compas,\n",
    "#                          [g / 8 for g in [*range(1, 21, 1)]], n_bins=[6])\n",
    "# frw_logit_compas = reweight(LogisticRegression(random_state=state, max_iter=1000), 'logit', df_compas, 'compas',\n",
    "#                             cat_cols_compas, nom_cols_compas, [g / 10 for g in [*range(1, 21, 1)]], n_bins=[6])\n",
    "\n",
    "# frw_nbs_ar = reweight(None, 'nbs', df_ar, 'ar', cat_cols_ar, nom_cols_ar, [g / 2.5 for g in [*range(1, 21, 1)]])\n",
    "# frw_dt_ar = reweight(dt_clf, 'dt', df_ar, 'ar', cat_cols_ar, nom_cols_ar, [g / 2 for g in [*range(1, 21, 1)]])\n",
    "# frw_logit_ar = reweight(LogisticRegression(random_state=state, max_iter=2000), 'logit', df_ar, 'ar', cat_cols_ar,\n",
    "#                         nom_cols_ar, [g / 2 for g in [*range(1, 21, 1)]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee7c9be-b073-4e10-b597-f01b61a035f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fair Preferential Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "63d7b566-f067-48ff-b24e-fb72163d6a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(clf, clf_name, df, df_name, cat_cols, nom_cols, betas, test=True, d_matrix=np.empty(0), m=np.nan,\n",
    "           n_bins=[10], drop_s=False, print_repeats=False, print_metrics=True, export=True, no_print=False):\n",
    "    \"\"\"\n",
    "        Applies FPS on training set\n",
    "\n",
    "        :param clf: instance of classifier (use clf=None for NBS)\n",
    "        :param clf_name: name of classifier\n",
    "        :param df: dataframe (column 0 = class_label (positive decision = 1),\n",
    "        column 1 = sensitive attribute (deprived group = 1), column 2 = explanatory attribute)\n",
    "        :param df_name: name of dataset\n",
    "        :param cat_cols: list with column names of categorical attributes in df (needed for NBS)\n",
    "        :param nom_cols: list with column names of nominal attributes in df (needed for one-hot-encoding)\n",
    "        :param betas: list with beta parameters to tune accuracy-fairness (default=None)\n",
    "        :param test: whether to make predictions for the test or validation set (default=False)\n",
    "        :param d_matrix: ndarray with distance matrix for measuring individual unfairness U (default=np.empty(0))\n",
    "        :param m: m for measuring individual unfairness U using m-NN (default=np.nan)\n",
    "        :param n_bins: number of bins used to discretize the explanatory attribute (default=10)\n",
    "        :param drop_s: whether to drop the sensitive attribute for training/prediction or not (default=False)\n",
    "        :param print_repeats: print percentage of sampled instances and repeats (default=False)\n",
    "        :param print_metrics: print dataframe with metrics (default=True)\n",
    "        :param export: whether to export the metrics (default=True)\n",
    "        :param no_print: whether to not print anything or print everything (default=False,\n",
    "        =True when tuning hyperparameters for DT)\n",
    "        :return: dataframe with metrics, where the indices are the different parameter values\n",
    "    \"\"\"\n",
    "\n",
    "    if clf_name == 'knn':\n",
    "        save_name = str(clf.get_params()['n_neighbors']) + clf_name[1:] + '_' + df_name\n",
    "    else:\n",
    "        save_name = clf_name + '_' + df_name\n",
    "    if not no_print:\n",
    "        print(' ' * 50 + clf_name + ' - ' + df_name)\n",
    "    if export:\n",
    "        if not test:\n",
    "            pd.DataFrame().to_excel(f'{m_path}fps_{save_name}_val.xlsx')\n",
    "        else:\n",
    "            pd.DataFrame().to_excel(f'{m_path}fps_{save_name}_te.xlsx')\n",
    "\n",
    "    y_pr_val_0, y_pr_te_0 = train(clf, clf_name, df, cat_cols, nom_cols, test=test, drop_s=drop_s, no_print=no_print)\n",
    "\n",
    "    if not test:\n",
    "        fnr_d, fpr_d, fnr_f, fpr_f, d_ix, f_ix = get_misclassification_metrics(y_pr_val_0)\n",
    "    else:\n",
    "        fnr_d, fpr_d, fnr_f, fpr_f, d_ix, f_ix = get_misclassification_metrics(y_pr_te_0)\n",
    "\n",
    "    if print_repeats:\n",
    "        d_fn_percentage = (d_ix.shape[0] / df.shape[0]) * 100\n",
    "        f_fp_percentage = (f_ix.shape[0] / df.shape[0]) * 100\n",
    "        print(f'X^d oversampled: {round(d_fn_percentage, 2)}%')\n",
    "        print(f'X^f oversampled: {round(f_fp_percentage, 2)}%')\n",
    "        print(f'#Oversampled (β=1) for X^d: {floor(len(d_ix) * fnr_d / fnr_f)}')\n",
    "        print(f'#Oversampled (β=1) for X^f: {floor(len(f_ix) * fpr_d / fpr_f)}')\n",
    "        print()\n",
    "\n",
    "    # k-NN/DT/logit cannot work with nominal attributes!\n",
    "    if clf_name == 'knn' or clf_name == 'dt':\n",
    "        df_enc = pd.get_dummies(df, columns=nom_cols.copy())\n",
    "    elif clf_name == 'logit':\n",
    "        df_enc = pd.get_dummies(df, columns=nom_cols.copy(), drop_first=True)\n",
    "    else:\n",
    "        df_enc = df.copy()\n",
    "\n",
    "    if drop_s:\n",
    "        df_enc = df_enc.drop(df_enc.columns[1], axis=1)\n",
    "\n",
    "    # First list item are beta parameters, list items after are dataframes for each beta \n",
    "    # (first dataframe is without sampling)\n",
    "    betas.insert(0, 'baseline')\n",
    "    dataframes = [betas, df_enc.copy()]\n",
    "\n",
    "    for beta in betas[1:]:\n",
    "        df_enc['ix'] = df_enc.index\n",
    "        repeats_d = ceil(beta * fnr_d / fnr_f)\n",
    "        repeats_f = ceil(beta * fpr_d / fpr_f)\n",
    "        # Rounded up #instances (ceil) is removed, so rounded down (floor) #instances stay\n",
    "        remove_d = ceil((repeats_d - (beta * fnr_d / fnr_f)) * len(d_ix))\n",
    "        remove_f = ceil((repeats_f - (beta * fpr_d / fpr_f)) * len(f_ix))\n",
    "\n",
    "        df_d_sampled = pd.DataFrame(np.repeat(df_enc.loc[d_ix].values, repeats_d, axis=0),\n",
    "                                    columns=list(df_enc.columns))\n",
    "        df_f_sampled = pd.DataFrame(np.repeat(df_enc.loc[f_ix].values, repeats_f, axis=0),\n",
    "                                    columns=list(df_enc.columns))\n",
    "\n",
    "        df_d_sampled = df_d_sampled.iloc[:-remove_d]\n",
    "        df_f_sampled = df_f_sampled.iloc[:-remove_f]\n",
    "\n",
    "        df_new = pd.concat([df_enc.copy(), df_d_sampled.copy(), df_f_sampled.copy()])\n",
    "        df_new = df_new.set_index('ix')\n",
    "\n",
    "        dataframes.append(df_new)\n",
    "\n",
    "    y_pr_val_1, y_pr_te_1 = train(clf, clf_name, df, cat_cols, nom_cols, 'fps', dataframes, test, drop_s, no_print)\n",
    "\n",
    "    if not test:\n",
    "        metrics_df = get_metrics(y_pr_val_1, df, d_matrix, m, df_name, cat_cols, n_bins=n_bins)\n",
    "    else:\n",
    "        metrics_df = get_metrics(y_pr_te_1, df, d_matrix, m, df_name, cat_cols, n_bins=n_bins)\n",
    "\n",
    "    if export:\n",
    "        if not test:\n",
    "            metrics_df.to_excel(f'{m_path}fps_{save_name}_val.xlsx')\n",
    "        else:\n",
    "            metrics_df.to_excel(f'{m_path}fps_{save_name}_te.xlsx')\n",
    "    if print_metrics:\n",
    "        print(metrics_df)\n",
    "    if not no_print:\n",
    "        print('-' * 100)\n",
    "\n",
    "    return metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a5c9d002-a275-4763-8378-b2280ea283f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fps_nbs_adult = sample(None, 'nbs', df_adult, 'adult', cat_cols_adult, nom_cols_adult,\n",
    "#                        [b / 3.2 for b in [*range(0, 21, 1)]])\n",
    "# fps_1nn_adult = sample(KNeighborsClassifier(n_neighbors=1), 'knn', df_adult, 'adult', cat_cols_adult, nom_cols_adult,\n",
    "#                        [b / 2.5 for b in [*range(0, 21, 1)]])\n",
    "# fps_3nn_adult = sample(KNeighborsClassifier(n_neighbors=3), 'knn', df_adult, 'adult', cat_cols_adult, nom_cols_adult,\n",
    "#                        [b * 2.5 for b in [*range(0, 21, 1)]])\n",
    "# fps_7nn_adult = sample(KNeighborsClassifier(n_neighbors=7), 'knn', df_adult, 'adult', cat_cols_adult, nom_cols_adult,\n",
    "#                        [b / 3.2 for b in [*range(0, 21, 1)]])\n",
    "# fps_dt_adult = sample(dt_clf, 'dt', df_adult, 'adult', cat_cols_adult, nom_cols_adult,\n",
    "#                       [b / 5 for b in [*range(0, 21, 1)]])\n",
    "# fps_logit_adult = sample(LogisticRegression(random_state=state, max_iter=5000), 'logit', df_adult, 'adult',\n",
    "#                          cat_cols_adult, nom_cols_adult, [b / 5 for b in [*range(0, 21, 1)]])\n",
    "\n",
    "# fps_nbs_compas = sample(None, 'nbs', df_compas, 'compas', cat_cols_compas, nom_cols_compas,\n",
    "#                         [b / 4 for b in [*range(0, 21, 1)]], n_bins=[6])\n",
    "# fps_1nn_compas = sample(KNeighborsClassifier(n_neighbors=1), 'knn', df_compas, 'compas', cat_cols_compas,\n",
    "#                         nom_cols_compas, [b / 1 for b in [*range(0, 21, 1)]], n_bins=[6])\n",
    "# fps_3nn_compas = sample(KNeighborsClassifier(n_neighbors=3), 'knn', df_compas, 'compas', cat_cols_compas,\n",
    "#                         nom_cols_compas, [b / 5 for b in [*range(0, 21, 1)]], n_bins=[6])\n",
    "# fps_7nn_compas = sample(KNeighborsClassifier(n_neighbors=7), 'knn', df_compas, 'compas', cat_cols_compas,\n",
    "#                         nom_cols_compas, [b / 5 for b in [*range(0, 21, 1)]], n_bins=[6])\n",
    "# fps_dt_compas = sample(dt_clf, 'dt', df_compas, 'compas', cat_cols_compas, nom_cols_compas,\n",
    "#                        [b / 10 for b in [*range(0, 21, 1)]], n_bins=[6])\n",
    "# fps_logit_compas = sample(LogisticRegression(random_state=state, max_iter=1000), 'logit', df_compas, 'compas',\n",
    "#                           cat_cols_compas, nom_cols_compas, [b / 25 for b in [*range(0, 21, 1)]], n_bins=[6])\n",
    "\n",
    "# fps_nbs_ar = sample(None, 'nbs', df_ar, 'ar', cat_cols_ar, nom_cols_ar, [b / 3.2 for b in [*range(0, 21, 1)]])\n",
    "# fps_1nn_ar = sample(KNeighborsClassifier(n_neighbors=1), 'knn', df_ar, 'ar', cat_cols_ar, nom_cols_ar,\n",
    "#                     [b / 5 for b in [*range(0, 21, 1)]])\n",
    "# fps_3nn_ar = sample(KNeighborsClassifier(n_neighbors=3), 'knn', df_ar, 'ar', cat_cols_ar, nom_cols_ar,\n",
    "#                     [b / 8 for b in [*range(0, 21, 1)]])\n",
    "# fps_7nn_ar = sample(KNeighborsClassifier(n_neighbors=7), 'knn', df_ar, 'ar', cat_cols_ar, nom_cols_ar,\n",
    "#                     [b / 12.5 for b in [*range(0, 21, 1)]])\n",
    "# fps_dt_ar = sample(dt_clf, 'dt', df_ar, 'ar', cat_cols_ar, nom_cols_ar, [b / 2 for b in [*range(0, 21, 1)]])\n",
    "# fps_logit_ar = sample(LogisticRegression(random_state=state, max_iter=2000), 'logit', df_ar, 'ar', cat_cols_ar,\n",
    "#                       nom_cols_ar, [b / 2.5 for b in [*range(0, 21, 1)]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da42f80b-c864-492b-8f61-dc463006e790",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fair Relabeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c13bfdd5-1786-4756-843c-ce23ce4936c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel(clf, clf_name, df, df_name, d_matrix, m, cat_cols, nom_cols, mus, test=True, n_bins=[10], t=0,\n",
    "            drop_s=False, print_metrics=True, export=True):\n",
    "    \"\"\"\n",
    "        Applies FRL on training set\n",
    "\n",
    "        :param clf: instance of classifier (use clf=None for NBS)\n",
    "        :param clf_name: name of classifier\n",
    "        :param df: dataframe (column 0 = class_label (positive decision = 1),\n",
    "        column 1 = sensitive attribute (deprived group = 1), column 2 = explanatory attribute)\n",
    "        :param df_name: name of dataset in df\n",
    "        :param d_matrix: ndarray with distance matrix\n",
    "        :param m: m for measuring individual unfairness U\n",
    "        :param cat_cols: list with column names of categorical attributes in df (needed for NBS)\n",
    "        :param nom_cols: list with column names of nominal attributes in df (needed for one-hot-encoding)\n",
    "        :param mus: list with mu parameters to tune accuracy-fairness\n",
    "        :param test: whether to make predictions for the test or validation set (default=False)\n",
    "        :param n_bins: number of bins used to discretize the explanatory attribute (default=10)\n",
    "        :param t: unfairness threshold for (score > t ⇒ unfair, default=0)\n",
    "        :param drop_s: whether to drop the sensitive attribute for training/prediction or not (default=False)\n",
    "        :param print_metrics: print dataframe with metrics (default=True)\n",
    "        :param export: whether to export the metrics (default=True)\n",
    "        :return: dataframe with metrics\n",
    "    \"\"\"\n",
    "\n",
    "    if clf_name == 'knn':\n",
    "        save_name = str(clf.get_params()['n_neighbors']) + clf_name[1:] + '_' + df_name\n",
    "    else:\n",
    "        save_name = clf_name + '_' + df_name\n",
    "    print(' ' * 50 + clf_name + ' - ' + df_name)\n",
    "    if export:\n",
    "        if not test:\n",
    "            pd.DataFrame().to_excel(f'{m_path}frl_{save_name}_val.xlsx')\n",
    "        else:\n",
    "            pd.DataFrame().to_excel(f'{m_path}frl_{save_name}_te.xlsx')\n",
    "\n",
    "    u_d, u_f, _, _ = get_unfair_instances(df.to_numpy(), d_matrix, m, df_name, t)\n",
    "\n",
    "    # DT/k-NN/logit cannot work with nominal attributes\n",
    "    if clf_name == 'dt' or clf_name == 'knn':        \n",
    "        df_enc = pd.get_dummies(df, columns=nom_cols)\n",
    "    elif clf_name == 'logit':\n",
    "        df_enc = pd.get_dummies(df, columns=nom_cols, drop_first=True)\n",
    "    else:\n",
    "        df_enc = df.copy()\n",
    "\n",
    "    dfs_frl = []\n",
    "    mus_copy = mus.copy()\n",
    "    mus_copy.insert(0, 'baseline')\n",
    "    mus_copy.insert(1, 'rl')\n",
    "    dfs_frl.append(mus_copy)\n",
    "\n",
    "    dfs_frl.append(df_enc)\n",
    "    df_rl = df_enc.copy()\n",
    "    # RL (Luong et al., 2011)\n",
    "    df_rl.iloc[u_d[:, 0].astype(int), 0] = 1\n",
    "    dfs_frl.append(df_rl)\n",
    "\n",
    "    u_d = np.hstack((u_d, np.ones((len(u_d), 1))))\n",
    "    u_f = np.hstack((u_f, np.zeros((len(u_f), 1))))\n",
    "    u = np.vstack((u_d, u_f))\n",
    "    # Columns indices of u: 0=index , 1=unfairness score, 2=k (# instanes d<m), 3=sensitive attribute\n",
    "    # Sort on k first then sort on unfairness score\n",
    "    u = u[np.lexsort((-u[:, 2], -u[:, 1]))]\n",
    "\n",
    "    # FRL for different mu values\n",
    "    for mu in mus:\n",
    "        df_frl = df_enc.copy()\n",
    "        n_u = round(u.shape[0] * mu)\n",
    "        u_01 = u[:n_u, :]\n",
    "\n",
    "        for i, row in enumerate(u_01):\n",
    "            if u_01[i, 3] == 1:\n",
    "                df_frl.iloc[u_01[i, 0].astype(int), 0] = 1\n",
    "            else:\n",
    "                df_frl.iloc[u_01[i, 0].astype(int), 0] = 0\n",
    "\n",
    "        dfs_frl.append(df_frl)\n",
    "\n",
    "    y_pr_val, y_pr_te = train(clf, clf_name, df, cat_cols, nom_cols, 'frl', dfs_frl, test, drop_s=drop_s)\n",
    "\n",
    "    if not test:\n",
    "        metrics_df = get_metrics(y_pr_val, df, d_matrix, m, df_name, cat_cols, n_bins, t)\n",
    "    else:\n",
    "        metrics_df = get_metrics(y_pr_te, df, d_matrix, m, df_name, cat_cols, n_bins, t)\n",
    "\n",
    "    if export:\n",
    "        if not test:\n",
    "            metrics_df.to_excel(f'{m_path}frl_{save_name}_val.xlsx')\n",
    "        else:\n",
    "            metrics_df.to_excel(f'{m_path}frl_{save_name}_te.xlsx')            \n",
    "    if print_metrics:\n",
    "        print(metrics_df)\n",
    "    print('-' * 100)\n",
    "\n",
    "    return metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "98d69966-6573-4335-96af-04200c53a0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "frl_mus = [m / 20 for m in [*range(0, 21, 1)]]\n",
    "\n",
    "# frl_nbs_adult = relabel(None, 'nbs', df_adult, 'adult', d_matrix_adult, m_adult, cat_cols_adult, nom_cols_adult,\n",
    "#                         frl_mus)\n",
    "# frl_1nn_adult = relabel(KNeighborsClassifier(n_neighbors=1), 'knn', df_adult, 'adult', d_matrix_adult, m_adult,\n",
    "#                         cat_cols_adult, nom_cols_adult, frl_mus)\n",
    "# frl_3nn_adult = relabel(KNeighborsClassifier(n_neighbors=3), 'knn', df_adult, 'adult', d_matrix_adult, m_adult,\n",
    "#                         cat_cols_adult, nom_cols_adult, frl_mus)\n",
    "# frl_7nn_adult = relabel(KNeighborsClassifier(n_neighbors=7), 'knn', df_adult, 'adult', d_matrix_adult, m_adult,\n",
    "#                         cat_cols_adult, nom_cols_adult, frl_mus)\n",
    "# frl_dt_adult = relabel(dt_clf, 'dt', df_adult, 'adult', d_matrix_adult, m_adult, cat_cols_adult, nom_cols_adult,\n",
    "#                        frl_mus)\n",
    "# frl_logit_adult = relabel(LogisticRegression(random_state=state, max_iter=5000), 'logit', df_adult, 'adult',\n",
    "#                           d_matrix_adult, m_adult, cat_cols_adult, nom_cols_adult, frl_mus)\n",
    "\n",
    "# frl_nbs_compas = relabel(None, 'nbs', df_compas, 'compas', d_matrix_compas, m_compas, cat_cols_compas, nom_cols_compas,\n",
    "#                          frl_mus, n_bins=[6])\n",
    "# frl_1nn_compas = relabel(KNeighborsClassifier(n_neighbors=1), 'knn', df_compas, 'compas', d_matrix_compas, m_compas,\n",
    "#                          cat_cols_compas, nom_cols_compas, frl_mus, n_bins=[6])\n",
    "# frl_3nn_compas = relabel(KNeighborsClassifier(n_neighbors=3), 'knn', df_compas, 'compas', d_matrix_compas, m_compas,\n",
    "#                          cat_cols_compas, nom_cols_compas, frl_mus, n_bins=[6])\n",
    "# frl_7nn_compas = relabel(KNeighborsClassifier(n_neighbors=7), 'knn', df_compas, 'compas', d_matrix_compas, m_compas,\n",
    "#                          cat_cols_compas, nom_cols_compas, frl_mus, n_bins=[6])\n",
    "# frl_dt_compas = relabel(dt_clf, 'dt', df_compas, 'compas', d_matrix_compas, m_compas, cat_cols_compas, nom_cols_compas,\n",
    "#                         frl_mus, n_bins=[6])\n",
    "# frl_logit_compas = relabel(LogisticRegression(random_state=state, max_iter=1000), 'logit', df_compas, 'compas',\n",
    "#                            d_matrix_compas, m_compas, cat_cols_compas, nom_cols_compas, frl_mus, n_bins=[6])\n",
    "\n",
    "# frl_nbs_ar = relabel(None, 'nbs', df_ar, 'ar', d_matrix_ar, m_ar, cat_cols_ar, nom_cols_ar, frl_mus)\n",
    "# frl_1nn_ar = relabel(KNeighborsClassifier(n_neighbors=1), 'knn', df_ar, 'ar', d_matrix_ar, m_ar, cat_cols_ar,\n",
    "#                      nom_cols_ar, frl_mus)\n",
    "# frl_3nn_ar = relabel(KNeighborsClassifier(n_neighbors=3), 'knn', df_ar, 'ar', d_matrix_ar, m_ar, cat_cols_ar,\n",
    "#                      nom_cols_ar, frl_mus)\n",
    "# frl_7nn_ar = relabel(KNeighborsClassifier(n_neighbors=7), 'knn', df_ar, 'ar', d_matrix_ar, m_ar, cat_cols_ar,\n",
    "#                      nom_cols_ar, frl_mus)\n",
    "# frl_dt_ar = relabel(dt_clf, 'dt', df_ar, 'ar', d_matrix_ar, m_ar, cat_cols_ar, nom_cols_ar, frl_mus)\n",
    "# frl_logit_ar = relabel(LogisticRegression(random_state=state, max_iter=2000), 'logit', df_ar, 'ar', d_matrix_ar, m_ar,\n",
    "#                        cat_cols_ar, nom_cols_ar, frl_mus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97af80aa-a36b-4e57-b32f-fb1afce25275",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot fairness trade-off"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c16117-d1a5-4926-a7f2-48bb97fe5ca7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Plot different classifiers for same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2732da2c-009a-42a0-a24f-85fbffc9411f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_metrics([[[pr_nbs_adult_nan, frw_nbs_adult_nan, fps_nbs_adult_nan, frl_nbs_adult], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#               [[pr_7nn_adult_nan, fps_7nn_adult_nan, frl_7nn_adult], ['PR', 'FPS', 'FRL'], 2],\n",
    "#               [[pr_dt_adult_nan, frw_dt_adult_nan, fps_dt_adult_nan, frl_dt_adult], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#               [[pr_logit_adult_nan, frw_logit_adult_nan, fps_logit_adult_nan, frl_logit_adult],\n",
    "#                ['PR', 'FRW', 'FPS', 'FRL'], 3]], 'adult')\n",
    "# plot_metrics([[[pr_nbs_adult_u, frw_nbs_adult_u, fps_nbs_adult_u, frl_nbs_adult], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#               [[pr_7nn_adult_u, fps_7nn_adult_u, frl_7nn_adult], ['PR', 'FPS', 'FRL'], 2],\n",
    "#               [[pr_dt_adult_u, frw_dt_adult_u, fps_dt_adult_u, frl_dt_adult], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#               [[pr_logit_adult_u, frw_logit_adult_u, fps_logit_adult_u, frl_logit_adult], ['PR', 'FRW', 'FPS', 'FRL'],\n",
    "#                3]], 'adult', 0)\n",
    "\n",
    "# plot_metrics([[[pr_nbs_compas, frw_nbs_compas, fps_nbs_compas, frl_nbs_compas], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#               [[pr_7nn_compas, fps_7nn_compas, frl_7nn_compas], ['PR', 'FPS', 'FRL'], 2],\n",
    "#               [[pr_dt_compas, frw_dt_compas, fps_dt_compas, frl_dt_compas], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#               [[pr_logit_compas, frw_logit_compas, fps_logit_compas, frl_logit_compas], ['PR', 'FRW', 'FPS', 'FRL'],\n",
    "#                3]], 'compas')\n",
    "# plot_metrics([[[pr_nbs_compas, frw_nbs_compas, fps_nbs_compas, frl_nbs_compas], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#               [[pr_7nn_compas, fps_7nn_compas, frl_7nn_compas], ['PR', 'FPS', 'FRL'], 2],\n",
    "#               [[pr_dt_compas, frw_dt_compas, fps_dt_compas, frl_dt_compas], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#               [[pr_logit_compas, frw_logit_compas, fps_logit_compas, frl_logit_compas], ['PR', 'FRW', 'FPS', 'FRL'],\n",
    "#                3]], 'compas', 0)\n",
    "\n",
    "# plot_metrics([[[pr_nbs_ar, frw_nbs_ar, fps_nbs_ar, frl_nbs_ar], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#               [[pr_7nn_ar, fps_7nn_ar, frl_7nn_ar], ['PR', 'FPS', 'FRL'], 2],\n",
    "#               [[pr_dt_ar, frw_dt_ar, fps_dt_ar, frl_dt_ar], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#               [[pr_logit_ar, frw_logit_ar, fps_logit_ar, frl_logit_ar], ['PR', 'FRW', 'FPS', 'FRL'], 3]], 'ar')\n",
    "# plot_metrics([[[pr_nbs_ar, frw_nbs_ar, fps_nbs_ar, frl_nbs_ar], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#               [[pr_7nn_ar, fps_7nn_ar, frl_7nn_ar], ['PR', 'FPS', 'FRL'], 2],\n",
    "#               [[pr_dt_ar, frw_dt_ar, fps_dt_ar, frl_dt_ar], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#               [[pr_logit_ar, frw_logit_ar, fps_logit_ar, frl_logit_ar], ['PR', 'FRW', 'FPS', 'FRL'], 3]], 'ar', 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ec7bf2-a4a7-45d3-b358-54054e267d40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Plot same classifier for different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9ec0770a-f71f-44a5-8e57-229e85544461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_metrics(\n",
    "#     [[[pr_nbs_adult_nan, frw_nbs_adult_nan, fps_nbs_adult_nan, frl_nbs_adult], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#      [[pr_nbs_compas, frw_nbs_compas, fps_nbs_compas, frl_nbs_compas], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#      [[pr_nbs_ar, frw_nbs_ar, fps_nbs_ar, frl_nbs_ar], ['PR', 'FRW', 'FPS', 'FRL'], 3]], 'nbs')\n",
    "# plot_metrics([[[pr_nbs_adult_u, frw_nbs_adult_u, fps_nbs_adult_u, frl_nbs_adult], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#               [[pr_nbs_compas, frw_nbs_compas, fps_nbs_compas, frl_nbs_compas], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#               [[pr_nbs_ar, frw_nbs_ar, fps_nbs_ar, frl_nbs_ar], ['PR', 'FRW', 'FPS', 'FRL'], 3]], 'nbs', 0)\n",
    "\n",
    "# plot_metrics([[[pr_7nn_adult_nan, fps_7nn_adult_nan, frl_7nn_adult], ['PR', 'FPS', 'FRL'], 2],\n",
    "#               [[pr_7nn_compas, fps_7nn_compas, frl_7nn_compas], ['PR', 'FPS', 'FRL'], 2],\n",
    "#               [[pr_7nn_ar, fps_7nn_ar, frl_7nn_ar], ['PR', 'FPS', 'FRL'], 2]], '7nn')\n",
    "# plot_metrics([[[pr_7nn_adult_u, fps_7nn_adult_u, frl_7nn_adult], ['PR', 'FPS', 'FRL'], 2],\n",
    "#               [[pr_7nn_compas, fps_7nn_compas, frl_7nn_compas], ['PR', 'FPS', 'FRL'], 2],\n",
    "#               [[pr_7nn_ar, fps_7nn_ar, frl_7nn_ar], ['PR', 'FPS', 'FRL'], 2]], '7nn', 0)\n",
    "\n",
    "# plot_metrics([[[pr_dt_adult_nan, frw_dt_adult_nan, fps_dt_adult_nan, frl_dt_adult], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#               [[pr_dt_compas, frw_dt_compas, fps_dt_compas, frl_dt_compas], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#               [[pr_dt_ar, frw_dt_ar, fps_dt_ar, frl_dt_ar], ['PR', 'FRW', 'FPS', 'FRL'], 3]], 'dt')\n",
    "# plot_metrics([[[pr_dt_adult_u, frw_dt_adult_u, fps_dt_adult_u, frl_dt_adult], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#               [[pr_dt_compas, frw_dt_compas, fps_dt_compas, frl_dt_compas], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#               [[pr_dt_ar, frw_dt_ar, fps_dt_ar, frl_dt_ar], ['PR', 'FRW', 'FPS', 'FRL'], 3]], 'dt', 0)\n",
    "\n",
    "# plot_metrics(\n",
    "#     [[[pr_logit_adult_nan, frw_logit_adult_nan, fps_logit_adult_nan, frl_logit_adult], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#      [[pr_logit_compas, frw_logit_compas, fps_logit_compas, frl_logit_compas], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#      [[pr_logit_ar, frw_logit_ar, fps_logit_ar, frl_logit_ar], ['PR', 'FRW', 'FPS', 'FRL'], 3]], 'logit')\n",
    "# plot_metrics(\n",
    "#     [[[pr_logit_adult_u, frw_logit_adult_u, fps_logit_adult_u, frl_logit_adult], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#      [[pr_logit_compas, frw_logit_compas, fps_logit_compas, frl_logit_compas], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#      [[pr_logit_ar, frw_logit_ar, fps_logit_ar, frl_logit_ar], ['PR', 'FRW', 'FPS', 'FRL'], 3]], 'logit', 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1f424426-2ac0-42b5-bacd-7ba74e2d3d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_metrics([[[pr_1nn_adult_nan, pr_3nn_adult_nan, pr_7nn_adult_nan], ['k=1', 'k=3', 'k=7'], 3],\n",
    "#               [[pr_1nn_compas, pr_3nn_compas, pr_7nn_compas], ['k=1', 'k=3', 'k=7'], 3],\n",
    "#               [[pr_1nn_ar, pr_3nn_ar, pr_7nn_ar], ['k=1', 'k=3', 'k=7'], 3]], 'pr_knn')\n",
    "# plot_metrics([[[pr_1nn_adult_u, pr_3nn_adult_u, pr_7nn_adult_u], ['k=1', 'k=3', 'k=7'], 3],\n",
    "#               [[pr_1nn_compas, pr_3nn_compas, pr_7nn_compas], ['k=1', 'k=3', 'k=7'], 3],\n",
    "#               [[pr_1nn_ar, pr_3nn_ar, pr_7nn_ar], ['k=1', 'k=3', 'k=7'], 3]], 'pr_knn', 0)\n",
    "\n",
    "# plot_metrics([[[fps_1nn_adult_nan, fps_3nn_adult_nan, fps_7nn_adult_nan], ['k=1', 'k=3', 'k=7'], 3],\n",
    "#               [[fps_1nn_compas, fps_3nn_compas, fps_7nn_compas], ['k=1', 'k=3', 'k=7'], 3],\n",
    "#               [[fps_1nn_ar, fps_3nn_ar, fps_7nn_ar], ['k=1', 'k=3', 'k=7'], 3]], 'fps_knn')\n",
    "# plot_metrics([[[fps_1nn_adult_u, fps_3nn_adult_u, fps_7nn_adult_u], ['k=1', 'k=3', 'k=7'], 3],\n",
    "#               [[fps_1nn_compas, fps_3nn_compas, fps_7nn_compas], ['k=1', 'k=3', 'k=7'], 3],\n",
    "#               [[fps_1nn_ar, fps_3nn_ar, fps_7nn_ar], ['k=1', 'k=3', 'k=7'], 3]], 'fps_knn', 0)\n",
    "\n",
    "# plot_metrics([[[frl_1nn_adult, frl_3nn_adult, frl_7nn_adult], ['k=1', 'k=3', 'k=7']],\n",
    "#               [[frl_1nn_compas, frl_3nn_compas, frl_7nn_compas], ['k=1', 'k=3', 'k=7']],\n",
    "#               [[frl_1nn_ar, frl_3nn_ar, frl_7nn_ar], ['k=1', 'k=3', 'k=7']]], 'frl_knn')\n",
    "# plot_metrics([[[frl_1nn_adult, frl_3nn_adult, frl_7nn_adult], ['k=1', 'k=3', 'k=7']],\n",
    "#               [[frl_1nn_compas, frl_3nn_compas, frl_7nn_compas], ['k=1', 'k=3', 'k=7']],\n",
    "#               [[frl_1nn_ar, frl_3nn_ar, frl_7nn_ar], ['k=1', 'k=3', 'k=7']]], 'frl_knn', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6673d852-d7bf-4dd2-809b-b5da5573fa4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Plot same classifier/dataset for D_u & U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "af4a32b3-47bd-4003-891f-2de24030397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_metrics_i(\n",
    "#     [[pr_nbs_adult_nan, frw_nbs_adult_nan, fps_nbs_adult_nan, frl_nbs_adult], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#     'nbs_adult_nan')\n",
    "# plot_metrics_i([[pr_nbs_adult_u, frw_nbs_adult_u, fps_nbs_adult_u, frl_nbs_adult], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#                'nbs_adult_u')\n",
    "# plot_metrics_i([[pr_nbs_compas, frw_nbs_compas, fps_nbs_compas, frl_nbs_compas], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#                'nbs_compas')\n",
    "# plot_metrics_i([[pr_nbs_ar, frw_nbs_ar, fps_nbs_ar, frl_nbs_ar], ['PR', 'FRW', 'FPS', 'FRL'], 3], 'nbs_ar')\n",
    "\n",
    "# plot_metrics_i([[pr_7nn_adult_nan, fps_7nn_adult_nan, frl_7nn_adult], ['PR', 'FPS', 'FRL'], 2], '7nn_adult_nan')\n",
    "# plot_metrics_i([[pr_7nn_adult_u, fps_7nn_adult_u, frl_7nn_adult], ['PR', 'FPS', 'FRL'], 2], '7nn_adult_u')\n",
    "# plot_metrics_i([[pr_7nn_compas, fps_7nn_compas, frl_7nn_compas], ['PR', 'FPS', 'FRL'], 2], '7nn_compas')\n",
    "# plot_metrics_i([[pr_7nn_ar, fps_7nn_ar, frl_7nn_ar], ['PR', 'FPS', 'FRL'], 2], '7nn_ar')\n",
    "\n",
    "# plot_metrics_i([[pr_dt_adult_nan, frw_dt_adult_nan, fps_dt_adult_nan, frl_dt_adult], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#                'dt_adult_nan')\n",
    "# plot_metrics_i([[pr_dt_adult_u, frw_dt_adult_u, fps_dt_adult_u, frl_dt_adult], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#                'dt_adult_u')\n",
    "# plot_metrics_i([[pr_dt_compas, frw_dt_compas, fps_dt_compas, frl_dt_compas], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#                'dt_compas')\n",
    "# plot_metrics_i([[pr_dt_ar, frw_dt_ar, fps_dt_ar, frl_dt_ar], ['PR', 'FRW', 'FPS', 'FRL'], 3], 'dt_ar')\n",
    "\n",
    "# plot_metrics_i(\n",
    "#     [[pr_logit_adult_nan, frw_logit_adult_nan, fps_logit_adult_nan, frl_logit_adult], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#     'logit_adult_nan')\n",
    "# plot_metrics_i(\n",
    "#     [[pr_logit_adult_u, frw_logit_adult_u, fps_logit_adult_u, frl_logit_adult], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#     'logit_adult_u')\n",
    "# plot_metrics_i(\n",
    "#     [[pr_logit_compas, frw_logit_compas, fps_logit_compas, frl_logit_compas], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#     'logit_compas')\n",
    "# plot_metrics_i([[pr_logit_ar, frw_logit_ar, fps_logit_ar, frl_logit_ar], ['PR', 'FRW', 'FPS', 'FRL'], 3], 'logit_ar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1aeaaff3-0c8f-43c7-b0be-de873d80c901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_metrics_i([[pr_1nn_adult_nan, pr_3nn_adult_nan, pr_7nn_adult_nan], ['k=1', 'k=3', 'k=7']], 'pr_knn_adult_nan')\n",
    "# plot_metrics_i([[pr_1nn_adult_u, pr_3nn_adult_u, pr_7nn_adult_u], ['k=1', 'k=3', 'k=7']], 'pr_knn_adult_u')\n",
    "# plot_metrics_i([[pr_1nn_compas, pr_3nn_compas, pr_7nn_compas], ['k=1', 'k=3', 'k=7']], 'pr_knn_compas')\n",
    "# plot_metrics_i([[pr_1nn_ar, pr_3nn_ar, pr_7nn_ar], ['k=1', 'k=3', 'k=7']], 'pr_knn_ar')\n",
    "\n",
    "# plot_metrics_i([[fps_1nn_adult_nan, fps_3nn_adult_nan, fps_7nn_adult_nan], ['k=1', 'k=3', 'k=7']], 'fps_knn_adult_nan')\n",
    "# plot_metrics_i([[fps_1nn_adult_u, fps_3nn_adult_u, fps_7nn_adult_u], ['k=1', 'k=3', 'k=7']], 'fps_knn_adult_u')\n",
    "# plot_metrics_i([[fps_1nn_compas, fps_3nn_compas, fps_7nn_compas], ['k=1', 'k=3', 'k=7']], 'fps_knn_compas')\n",
    "# plot_metrics_i([[fps_1nn_ar, fps_3nn_ar, fps_7nn_ar], ['k=1', 'k=3', 'k=7']], 'fps_knn_ar')\n",
    "\n",
    "# plot_metrics_i([[frl_1nn_adult, frl_3nn_adult, frl_7nn_adult], ['k=1', 'k=3', 'k=7']], 'frl_knn_adult')\n",
    "# plot_metrics_i([[frl_1nn_compas, frl_3nn_compas, frl_7nn_compas], ['k=1', 'k=3', 'k=7']], 'frl_knn_compas')\n",
    "# plot_metrics_i([[frl_1nn_ar, frl_3nn_ar, frl_7nn_ar], ['k=1', 'k=3', 'k=7']], 'frl_knn_ar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53278b66-1f13-469c-8700-001be2d40fde",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Plot relationship between D_u & U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "064066a5-a927-4d75-966a-c0dca207d71c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_metrics_ii([[pr_nbs_adult_u, frw_nbs_adult_u, fps_nbs_adult_u, frl_nbs_adult], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#                 'nbs_adult_du_u')\n",
    "# plot_metrics_ii([[pr_nbs_compas, frw_nbs_compas, fps_nbs_compas, frl_nbs_compas], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#                 'nbs_compas_du_u')\n",
    "# plot_metrics_ii([[pr_nbs_ar, frw_nbs_ar, fps_nbs_ar, frl_nbs_ar], ['PR', 'FRW', 'FPS', 'FRL'], 3], 'nbs_ar_du_u')\n",
    "\n",
    "# plot_metrics_ii([[pr_7nn_adult_u, fps_7nn_adult_u, frl_7nn_adult], ['PR', 'FPS', 'FRL'], 2], '7nn_adult_du_u')\n",
    "# plot_metrics_ii([[pr_7nn_compas, fps_7nn_compas, frl_7nn_compas], ['PR', 'FPS', 'FRL'], 2], '7nn_compas_du_u')\n",
    "# plot_metrics_ii([[pr_7nn_ar, fps_7nn_ar, frl_7nn_ar], ['PR', 'FPS', 'FRL'], 2], '7nn_ar_du_u')\n",
    "\n",
    "# plot_metrics_ii([[pr_dt_adult_u, frw_dt_adult_u, fps_dt_adult_u, frl_dt_adult], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#                 'dt_adult_du_u')\n",
    "# plot_metrics_ii([[pr_dt_compas, frw_dt_compas, fps_dt_compas, frl_dt_compas], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#                 'dt_compas_du_u')\n",
    "# plot_metrics_ii([[pr_dt_ar, frw_dt_ar, fps_dt_ar, frl_dt_ar], ['PR', 'FRW', 'FPS', 'FRL'], 3], 'dt_ar_du_u')\n",
    "\n",
    "# plot_metrics_ii(\n",
    "#     [[pr_logit_adult_u, frw_logit_adult_u, fps_logit_adult_u, frl_logit_adult], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#     'logit_adult_du_u')\n",
    "# plot_metrics_ii(\n",
    "#     [[pr_logit_compas, frw_logit_compas, fps_logit_compas, frl_logit_compas], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#     'logit_compas_du_u')\n",
    "# plot_metrics_ii([[pr_logit_ar, frw_logit_ar, fps_logit_ar, frl_logit_ar], ['PR', 'FRW', 'FPS', 'FRL'], 3],\n",
    "#                 'logit_ar_du_u')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
